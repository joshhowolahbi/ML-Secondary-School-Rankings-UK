{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Component Three",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNzxmM1J2eSAwzz+fUDwPKv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joshhowolahbi/ML-Secondary-School-Rankings-UK/blob/main/Component_Three.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8cJ9ens6Sc4"
      },
      "source": [
        "# Component 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YsrALQLg6Jtw",
        "outputId": "7ecb72cc-004e-4618-dc24-3ca2a7168795"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "from sklearn import metrics, neighbors, naive_bayes, preprocessing, linear_model, feature_selection\n",
        "from matplotlib.ticker import PercentFormatter\n",
        "print('setup complete')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "setup complete\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ae2lYH6FFMK9"
      },
      "source": [
        "**Basic ML Tasks**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWqxHr-u7uw-"
      },
      "source": [
        "Remove all the schools with a Rating of “Unknown”. Combine all the ratings that aren’t “Outstanding” or “Good” into a single rating of “Not Good”."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "oNoX4KT6-c8T",
        "outputId": "b20a3928-0d3d-4780-9d27-d05f78bdbc6f"
      },
      "source": [
        "com_ofs_df = pd.read_excel('Clean Combined OFSTED.xlsx')\n",
        "com_ofs_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>URN</th>\n",
              "      <th>LA</th>\n",
              "      <th>GENDER</th>\n",
              "      <th>RELCHAR</th>\n",
              "      <th>PNORG</th>\n",
              "      <th>PNORB</th>\n",
              "      <th>PSENELSE</th>\n",
              "      <th>PSENELK</th>\n",
              "      <th>PNUMEAL</th>\n",
              "      <th>PNUMENGFL</th>\n",
              "      <th>PNUMUNCFL</th>\n",
              "      <th>PNUMFSMEVER</th>\n",
              "      <th>PNUMFSM</th>\n",
              "      <th>PERCTOT</th>\n",
              "      <th>PPERSABS10</th>\n",
              "      <th>TPUP</th>\n",
              "      <th>P8PUP</th>\n",
              "      <th>ATT8SCR</th>\n",
              "      <th>P8MEA</th>\n",
              "      <th>P8CILOW</th>\n",
              "      <th>P8CIUPP</th>\n",
              "      <th>EBACCAPS</th>\n",
              "      <th>PTL2BASICS_94</th>\n",
              "      <th>PTL2BASICS_95</th>\n",
              "      <th>PTEBACC_E_PTQ_EE</th>\n",
              "      <th>PTEBACC_94</th>\n",
              "      <th>PTEBACC_95</th>\n",
              "      <th>PT5EM_94</th>\n",
              "      <th>P8_BANDING</th>\n",
              "      <th>OVERALL_DESTPER</th>\n",
              "      <th>NOT_SUSTAINEDPER</th>\n",
              "      <th>UNKNOWNPER</th>\n",
              "      <th>OVERALL_DESTPER_DIS</th>\n",
              "      <th>NOT_SUSTAINEDPER_DIS</th>\n",
              "      <th>UNKNOWNPER_DIS</th>\n",
              "      <th>Rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100049</td>\n",
              "      <td>202</td>\n",
              "      <td>Mixed</td>\n",
              "      <td>Does not apply</td>\n",
              "      <td>41.4</td>\n",
              "      <td>58.6</td>\n",
              "      <td>3.2</td>\n",
              "      <td>11.8</td>\n",
              "      <td>73.1</td>\n",
              "      <td>26.8</td>\n",
              "      <td>0.1</td>\n",
              "      <td>64.5</td>\n",
              "      <td>41.2</td>\n",
              "      <td>6.9</td>\n",
              "      <td>18.8</td>\n",
              "      <td>199</td>\n",
              "      <td>178</td>\n",
              "      <td>42.4</td>\n",
              "      <td>-0.09</td>\n",
              "      <td>-0.28</td>\n",
              "      <td>0.09</td>\n",
              "      <td>3.72</td>\n",
              "      <td>0.588</td>\n",
              "      <td>0.432</td>\n",
              "      <td>0.241</td>\n",
              "      <td>0.191</td>\n",
              "      <td>0.141</td>\n",
              "      <td>0.533</td>\n",
              "      <td>3</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.89</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.01</td>\n",
              "      <td>Good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100050</td>\n",
              "      <td>202</td>\n",
              "      <td>Girls</td>\n",
              "      <td>Does not apply</td>\n",
              "      <td>96.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.3</td>\n",
              "      <td>10.2</td>\n",
              "      <td>38.1</td>\n",
              "      <td>60.9</td>\n",
              "      <td>0.9</td>\n",
              "      <td>49.6</td>\n",
              "      <td>26.9</td>\n",
              "      <td>5.3</td>\n",
              "      <td>12.5</td>\n",
              "      <td>175</td>\n",
              "      <td>164</td>\n",
              "      <td>58.6</td>\n",
              "      <td>0.77</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.97</td>\n",
              "      <td>5.33</td>\n",
              "      <td>0.760</td>\n",
              "      <td>0.577</td>\n",
              "      <td>0.577</td>\n",
              "      <td>0.417</td>\n",
              "      <td>0.326</td>\n",
              "      <td>0.749</td>\n",
              "      <td>1</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.01</td>\n",
              "      <td>Good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100051</td>\n",
              "      <td>202</td>\n",
              "      <td>Mixed</td>\n",
              "      <td>Does not apply</td>\n",
              "      <td>45.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>11.1</td>\n",
              "      <td>82.6</td>\n",
              "      <td>17.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>6.7</td>\n",
              "      <td>19.2</td>\n",
              "      <td>154</td>\n",
              "      <td>139</td>\n",
              "      <td>42.1</td>\n",
              "      <td>-0.18</td>\n",
              "      <td>-0.40</td>\n",
              "      <td>0.03</td>\n",
              "      <td>3.77</td>\n",
              "      <td>0.591</td>\n",
              "      <td>0.403</td>\n",
              "      <td>0.604</td>\n",
              "      <td>0.201</td>\n",
              "      <td>0.071</td>\n",
              "      <td>0.526</td>\n",
              "      <td>3</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.85</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.06</td>\n",
              "      <td>Good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>100052</td>\n",
              "      <td>202</td>\n",
              "      <td>Mixed</td>\n",
              "      <td>Does not apply</td>\n",
              "      <td>47.5</td>\n",
              "      <td>52.5</td>\n",
              "      <td>2.4</td>\n",
              "      <td>6.9</td>\n",
              "      <td>55.8</td>\n",
              "      <td>44.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>54.2</td>\n",
              "      <td>22.8</td>\n",
              "      <td>5.4</td>\n",
              "      <td>14</td>\n",
              "      <td>200</td>\n",
              "      <td>188</td>\n",
              "      <td>44.6</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>-0.24</td>\n",
              "      <td>0.13</td>\n",
              "      <td>4.08</td>\n",
              "      <td>0.630</td>\n",
              "      <td>0.315</td>\n",
              "      <td>0.585</td>\n",
              "      <td>0.240</td>\n",
              "      <td>0.120</td>\n",
              "      <td>0.570</td>\n",
              "      <td>3</td>\n",
              "      <td>0.91</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0</td>\n",
              "      <td>Good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>100053</td>\n",
              "      <td>202</td>\n",
              "      <td>Mixed</td>\n",
              "      <td>Does not apply</td>\n",
              "      <td>33.7</td>\n",
              "      <td>66.3</td>\n",
              "      <td>6.2</td>\n",
              "      <td>13.4</td>\n",
              "      <td>28.2</td>\n",
              "      <td>70.3</td>\n",
              "      <td>1.5</td>\n",
              "      <td>47.1</td>\n",
              "      <td>26.2</td>\n",
              "      <td>6.3</td>\n",
              "      <td>18.5</td>\n",
              "      <td>136</td>\n",
              "      <td>128</td>\n",
              "      <td>47.2</td>\n",
              "      <td>-0.08</td>\n",
              "      <td>-0.30</td>\n",
              "      <td>0.14</td>\n",
              "      <td>4.29</td>\n",
              "      <td>0.662</td>\n",
              "      <td>0.471</td>\n",
              "      <td>0.515</td>\n",
              "      <td>0.368</td>\n",
              "      <td>0.265</td>\n",
              "      <td>0.625</td>\n",
              "      <td>3</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.03</td>\n",
              "      <td>Good</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      URN   LA GENDER  ... NOT_SUSTAINEDPER_DIS  UNKNOWNPER_DIS  Rating\n",
              "0  100049  202  Mixed  ...                 0.11            0.01    Good\n",
              "1  100050  202  Girls  ...                 0.04            0.01    Good\n",
              "2  100051  202  Mixed  ...                 0.09            0.06    Good\n",
              "3  100052  202  Mixed  ...                 0.13               0    Good\n",
              "4  100053  202  Mixed  ...                 0.07            0.03    Good\n",
              "\n",
              "[5 rows x 36 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zz7i7M-8_pF1",
        "outputId": "ea0f3c2d-5013-48eb-d3ba-13480a1fc2f7"
      },
      "source": [
        "com_ofs_df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3167, 36)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDmoCRPS_a7v",
        "outputId": "9a7f1636-23e6-48f1-ee1d-9197c0e72ee7"
      },
      "source": [
        "kwn_rt_df = com_ofs_df[~com_ofs_df.Rating.str.contains(\"Unknown\")]\n",
        "kwn_rt_df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2743, 36)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        },
        "id": "nUPTgcpDAkyG",
        "outputId": "dea1d2d5-7aba-40af-8319-54168da2350c"
      },
      "source": [
        "kwn_rt_df['Rating']=kwn_rt_df['Rating'].str.replace('Inadequate','Not Good')\n",
        "kwn_rt_df['Rating']=kwn_rt_df['Rating'].str.replace('Requires Improvement','Not Good')\n",
        "sns.countplot(y = kwn_rt_df['Rating'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f66ab6d74a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "PO3HLCGPjn-c",
        "outputId": "a75e891b-c724-4103-a6ca-fea6db73a637"
      },
      "source": [
        "ref_df = kwn_rt_df.copy()\n",
        "ref_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>URN</th>\n",
              "      <th>LA</th>\n",
              "      <th>GENDER</th>\n",
              "      <th>RELCHAR</th>\n",
              "      <th>PNORG</th>\n",
              "      <th>PNORB</th>\n",
              "      <th>PSENELSE</th>\n",
              "      <th>PSENELK</th>\n",
              "      <th>PNUMEAL</th>\n",
              "      <th>PNUMENGFL</th>\n",
              "      <th>PNUMUNCFL</th>\n",
              "      <th>PNUMFSMEVER</th>\n",
              "      <th>PNUMFSM</th>\n",
              "      <th>PERCTOT</th>\n",
              "      <th>PPERSABS10</th>\n",
              "      <th>TPUP</th>\n",
              "      <th>P8PUP</th>\n",
              "      <th>ATT8SCR</th>\n",
              "      <th>P8MEA</th>\n",
              "      <th>P8CILOW</th>\n",
              "      <th>P8CIUPP</th>\n",
              "      <th>EBACCAPS</th>\n",
              "      <th>PTL2BASICS_94</th>\n",
              "      <th>PTL2BASICS_95</th>\n",
              "      <th>PTEBACC_E_PTQ_EE</th>\n",
              "      <th>PTEBACC_94</th>\n",
              "      <th>PTEBACC_95</th>\n",
              "      <th>PT5EM_94</th>\n",
              "      <th>P8_BANDING</th>\n",
              "      <th>OVERALL_DESTPER</th>\n",
              "      <th>NOT_SUSTAINEDPER</th>\n",
              "      <th>UNKNOWNPER</th>\n",
              "      <th>OVERALL_DESTPER_DIS</th>\n",
              "      <th>NOT_SUSTAINEDPER_DIS</th>\n",
              "      <th>UNKNOWNPER_DIS</th>\n",
              "      <th>Rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100049</td>\n",
              "      <td>202</td>\n",
              "      <td>Mixed</td>\n",
              "      <td>Does not apply</td>\n",
              "      <td>41.4</td>\n",
              "      <td>58.6</td>\n",
              "      <td>3.2</td>\n",
              "      <td>11.8</td>\n",
              "      <td>73.1</td>\n",
              "      <td>26.8</td>\n",
              "      <td>0.1</td>\n",
              "      <td>64.5</td>\n",
              "      <td>41.2</td>\n",
              "      <td>6.9</td>\n",
              "      <td>18.8</td>\n",
              "      <td>199</td>\n",
              "      <td>178</td>\n",
              "      <td>42.4</td>\n",
              "      <td>-0.09</td>\n",
              "      <td>-0.28</td>\n",
              "      <td>0.09</td>\n",
              "      <td>3.72</td>\n",
              "      <td>0.588</td>\n",
              "      <td>0.432</td>\n",
              "      <td>0.241</td>\n",
              "      <td>0.191</td>\n",
              "      <td>0.141</td>\n",
              "      <td>0.533</td>\n",
              "      <td>3</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.89</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.01</td>\n",
              "      <td>Good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100050</td>\n",
              "      <td>202</td>\n",
              "      <td>Girls</td>\n",
              "      <td>Does not apply</td>\n",
              "      <td>96.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.3</td>\n",
              "      <td>10.2</td>\n",
              "      <td>38.1</td>\n",
              "      <td>60.9</td>\n",
              "      <td>0.9</td>\n",
              "      <td>49.6</td>\n",
              "      <td>26.9</td>\n",
              "      <td>5.3</td>\n",
              "      <td>12.5</td>\n",
              "      <td>175</td>\n",
              "      <td>164</td>\n",
              "      <td>58.6</td>\n",
              "      <td>0.77</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.97</td>\n",
              "      <td>5.33</td>\n",
              "      <td>0.760</td>\n",
              "      <td>0.577</td>\n",
              "      <td>0.577</td>\n",
              "      <td>0.417</td>\n",
              "      <td>0.326</td>\n",
              "      <td>0.749</td>\n",
              "      <td>1</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.01</td>\n",
              "      <td>Good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100051</td>\n",
              "      <td>202</td>\n",
              "      <td>Mixed</td>\n",
              "      <td>Does not apply</td>\n",
              "      <td>45.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>11.1</td>\n",
              "      <td>82.6</td>\n",
              "      <td>17.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>6.7</td>\n",
              "      <td>19.2</td>\n",
              "      <td>154</td>\n",
              "      <td>139</td>\n",
              "      <td>42.1</td>\n",
              "      <td>-0.18</td>\n",
              "      <td>-0.40</td>\n",
              "      <td>0.03</td>\n",
              "      <td>3.77</td>\n",
              "      <td>0.591</td>\n",
              "      <td>0.403</td>\n",
              "      <td>0.604</td>\n",
              "      <td>0.201</td>\n",
              "      <td>0.071</td>\n",
              "      <td>0.526</td>\n",
              "      <td>3</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.85</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.06</td>\n",
              "      <td>Good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>100052</td>\n",
              "      <td>202</td>\n",
              "      <td>Mixed</td>\n",
              "      <td>Does not apply</td>\n",
              "      <td>47.5</td>\n",
              "      <td>52.5</td>\n",
              "      <td>2.4</td>\n",
              "      <td>6.9</td>\n",
              "      <td>55.8</td>\n",
              "      <td>44.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>54.2</td>\n",
              "      <td>22.8</td>\n",
              "      <td>5.4</td>\n",
              "      <td>14</td>\n",
              "      <td>200</td>\n",
              "      <td>188</td>\n",
              "      <td>44.6</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>-0.24</td>\n",
              "      <td>0.13</td>\n",
              "      <td>4.08</td>\n",
              "      <td>0.630</td>\n",
              "      <td>0.315</td>\n",
              "      <td>0.585</td>\n",
              "      <td>0.240</td>\n",
              "      <td>0.120</td>\n",
              "      <td>0.570</td>\n",
              "      <td>3</td>\n",
              "      <td>0.91</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0</td>\n",
              "      <td>Good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>100053</td>\n",
              "      <td>202</td>\n",
              "      <td>Mixed</td>\n",
              "      <td>Does not apply</td>\n",
              "      <td>33.7</td>\n",
              "      <td>66.3</td>\n",
              "      <td>6.2</td>\n",
              "      <td>13.4</td>\n",
              "      <td>28.2</td>\n",
              "      <td>70.3</td>\n",
              "      <td>1.5</td>\n",
              "      <td>47.1</td>\n",
              "      <td>26.2</td>\n",
              "      <td>6.3</td>\n",
              "      <td>18.5</td>\n",
              "      <td>136</td>\n",
              "      <td>128</td>\n",
              "      <td>47.2</td>\n",
              "      <td>-0.08</td>\n",
              "      <td>-0.30</td>\n",
              "      <td>0.14</td>\n",
              "      <td>4.29</td>\n",
              "      <td>0.662</td>\n",
              "      <td>0.471</td>\n",
              "      <td>0.515</td>\n",
              "      <td>0.368</td>\n",
              "      <td>0.265</td>\n",
              "      <td>0.625</td>\n",
              "      <td>3</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.03</td>\n",
              "      <td>Good</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      URN   LA GENDER  ... NOT_SUSTAINEDPER_DIS  UNKNOWNPER_DIS  Rating\n",
              "0  100049  202  Mixed  ...                 0.11            0.01    Good\n",
              "1  100050  202  Girls  ...                 0.04            0.01    Good\n",
              "2  100051  202  Mixed  ...                 0.09            0.06    Good\n",
              "3  100052  202  Mixed  ...                 0.13               0    Good\n",
              "4  100053  202  Mixed  ...                 0.07            0.03    Good\n",
              "\n",
              "[5 rows x 36 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2QZ49yhRV9U"
      },
      "source": [
        "Estimating Baseline accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oXwQTkkbxfm"
      },
      "source": [
        "- This problem is a classification problem and the approach to use in estimating the baseline accuracy is the ZeroR Algorithm which predicts the class value of that is most common in the training set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HxH8Hw5eSXl"
      },
      "source": [
        "Estimating Accuraccy with other classifiers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgU7-1EEznFd"
      },
      "source": [
        "- To be able to perform the validation the Rating will be giving distinct value added to the column (Rating_Val) where **Outstanding=2, Good=1, Not Good=0**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "2OgFp2EF0IMP",
        "outputId": "3ed0775e-de41-4e8e-da44-8eb4baafec7c"
      },
      "source": [
        "rat_df=ref_df[['Rating']]\n",
        "rat_v_df = rat_df.replace(['Outstanding','Good','Not Good'], [2,1,0])\n",
        "ref_df['Rating_Val']=rat_v_df\n",
        "ref_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>URN</th>\n",
              "      <th>LA</th>\n",
              "      <th>GENDER</th>\n",
              "      <th>RELCHAR</th>\n",
              "      <th>PNORG</th>\n",
              "      <th>PNORB</th>\n",
              "      <th>PSENELSE</th>\n",
              "      <th>PSENELK</th>\n",
              "      <th>PNUMEAL</th>\n",
              "      <th>PNUMENGFL</th>\n",
              "      <th>PNUMUNCFL</th>\n",
              "      <th>PNUMFSMEVER</th>\n",
              "      <th>PNUMFSM</th>\n",
              "      <th>PERCTOT</th>\n",
              "      <th>PPERSABS10</th>\n",
              "      <th>TPUP</th>\n",
              "      <th>P8PUP</th>\n",
              "      <th>ATT8SCR</th>\n",
              "      <th>P8MEA</th>\n",
              "      <th>P8CILOW</th>\n",
              "      <th>P8CIUPP</th>\n",
              "      <th>EBACCAPS</th>\n",
              "      <th>PTL2BASICS_94</th>\n",
              "      <th>PTL2BASICS_95</th>\n",
              "      <th>PTEBACC_E_PTQ_EE</th>\n",
              "      <th>PTEBACC_94</th>\n",
              "      <th>PTEBACC_95</th>\n",
              "      <th>PT5EM_94</th>\n",
              "      <th>P8_BANDING</th>\n",
              "      <th>OVERALL_DESTPER</th>\n",
              "      <th>NOT_SUSTAINEDPER</th>\n",
              "      <th>UNKNOWNPER</th>\n",
              "      <th>OVERALL_DESTPER_DIS</th>\n",
              "      <th>NOT_SUSTAINEDPER_DIS</th>\n",
              "      <th>UNKNOWNPER_DIS</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Rating_Val</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100049</td>\n",
              "      <td>202</td>\n",
              "      <td>Mixed</td>\n",
              "      <td>Does not apply</td>\n",
              "      <td>41.4</td>\n",
              "      <td>58.6</td>\n",
              "      <td>3.2</td>\n",
              "      <td>11.8</td>\n",
              "      <td>73.1</td>\n",
              "      <td>26.8</td>\n",
              "      <td>0.1</td>\n",
              "      <td>64.5</td>\n",
              "      <td>41.2</td>\n",
              "      <td>6.9</td>\n",
              "      <td>18.8</td>\n",
              "      <td>199</td>\n",
              "      <td>178</td>\n",
              "      <td>42.4</td>\n",
              "      <td>-0.09</td>\n",
              "      <td>-0.28</td>\n",
              "      <td>0.09</td>\n",
              "      <td>3.72</td>\n",
              "      <td>0.588</td>\n",
              "      <td>0.432</td>\n",
              "      <td>0.241</td>\n",
              "      <td>0.191</td>\n",
              "      <td>0.141</td>\n",
              "      <td>0.533</td>\n",
              "      <td>3</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.89</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.01</td>\n",
              "      <td>Good</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100050</td>\n",
              "      <td>202</td>\n",
              "      <td>Girls</td>\n",
              "      <td>Does not apply</td>\n",
              "      <td>96.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.3</td>\n",
              "      <td>10.2</td>\n",
              "      <td>38.1</td>\n",
              "      <td>60.9</td>\n",
              "      <td>0.9</td>\n",
              "      <td>49.6</td>\n",
              "      <td>26.9</td>\n",
              "      <td>5.3</td>\n",
              "      <td>12.5</td>\n",
              "      <td>175</td>\n",
              "      <td>164</td>\n",
              "      <td>58.6</td>\n",
              "      <td>0.77</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.97</td>\n",
              "      <td>5.33</td>\n",
              "      <td>0.760</td>\n",
              "      <td>0.577</td>\n",
              "      <td>0.577</td>\n",
              "      <td>0.417</td>\n",
              "      <td>0.326</td>\n",
              "      <td>0.749</td>\n",
              "      <td>1</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.01</td>\n",
              "      <td>Good</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100051</td>\n",
              "      <td>202</td>\n",
              "      <td>Mixed</td>\n",
              "      <td>Does not apply</td>\n",
              "      <td>45.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>11.1</td>\n",
              "      <td>82.6</td>\n",
              "      <td>17.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>6.7</td>\n",
              "      <td>19.2</td>\n",
              "      <td>154</td>\n",
              "      <td>139</td>\n",
              "      <td>42.1</td>\n",
              "      <td>-0.18</td>\n",
              "      <td>-0.40</td>\n",
              "      <td>0.03</td>\n",
              "      <td>3.77</td>\n",
              "      <td>0.591</td>\n",
              "      <td>0.403</td>\n",
              "      <td>0.604</td>\n",
              "      <td>0.201</td>\n",
              "      <td>0.071</td>\n",
              "      <td>0.526</td>\n",
              "      <td>3</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.85</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.06</td>\n",
              "      <td>Good</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>100052</td>\n",
              "      <td>202</td>\n",
              "      <td>Mixed</td>\n",
              "      <td>Does not apply</td>\n",
              "      <td>47.5</td>\n",
              "      <td>52.5</td>\n",
              "      <td>2.4</td>\n",
              "      <td>6.9</td>\n",
              "      <td>55.8</td>\n",
              "      <td>44.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>54.2</td>\n",
              "      <td>22.8</td>\n",
              "      <td>5.4</td>\n",
              "      <td>14</td>\n",
              "      <td>200</td>\n",
              "      <td>188</td>\n",
              "      <td>44.6</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>-0.24</td>\n",
              "      <td>0.13</td>\n",
              "      <td>4.08</td>\n",
              "      <td>0.630</td>\n",
              "      <td>0.315</td>\n",
              "      <td>0.585</td>\n",
              "      <td>0.240</td>\n",
              "      <td>0.120</td>\n",
              "      <td>0.570</td>\n",
              "      <td>3</td>\n",
              "      <td>0.91</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0</td>\n",
              "      <td>Good</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>100053</td>\n",
              "      <td>202</td>\n",
              "      <td>Mixed</td>\n",
              "      <td>Does not apply</td>\n",
              "      <td>33.7</td>\n",
              "      <td>66.3</td>\n",
              "      <td>6.2</td>\n",
              "      <td>13.4</td>\n",
              "      <td>28.2</td>\n",
              "      <td>70.3</td>\n",
              "      <td>1.5</td>\n",
              "      <td>47.1</td>\n",
              "      <td>26.2</td>\n",
              "      <td>6.3</td>\n",
              "      <td>18.5</td>\n",
              "      <td>136</td>\n",
              "      <td>128</td>\n",
              "      <td>47.2</td>\n",
              "      <td>-0.08</td>\n",
              "      <td>-0.30</td>\n",
              "      <td>0.14</td>\n",
              "      <td>4.29</td>\n",
              "      <td>0.662</td>\n",
              "      <td>0.471</td>\n",
              "      <td>0.515</td>\n",
              "      <td>0.368</td>\n",
              "      <td>0.265</td>\n",
              "      <td>0.625</td>\n",
              "      <td>3</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.03</td>\n",
              "      <td>Good</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      URN   LA GENDER  ... UNKNOWNPER_DIS  Rating  Rating_Val\n",
              "0  100049  202  Mixed  ...           0.01    Good           1\n",
              "1  100050  202  Girls  ...           0.01    Good           1\n",
              "2  100051  202  Mixed  ...           0.06    Good           1\n",
              "3  100052  202  Mixed  ...              0    Good           1\n",
              "4  100053  202  Mixed  ...           0.03    Good           1\n",
              "\n",
              "[5 rows x 37 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cd7NkzVIuDNh"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-uaSQQlt_9s"
      },
      "source": [
        "- using k-fold cross validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msVleieneYWp"
      },
      "source": [
        "- K-Nearest Neighnour"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HAUdEf8edHf",
        "outputId": "02f63fc1-2817-4218-d70e-56dd03f9cc3b"
      },
      "source": [
        "X = ref_df[['PNORG','PNORB','PSENELSE','PSENELK','PNUMEAL','PNUMENGFL','PNUMUNCFL','PNUMFSM','P8PUP','ATT8SCR','P8MEA']].values\n",
        "y = ref_df['Rating_Val'].values\n",
        "clf = neighbors.KNeighborsClassifier()\n",
        "clf.fit(X,y)\n",
        "predictions_k = clf.predict(X)\n",
        "metrics.accuracy_score(y, predictions_k)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7302223842508203"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8SpNwCouYYi",
        "outputId": "e3a7712e-e496-4533-d782-473179ab8db9"
      },
      "source": [
        "scores_kN = cross_val_score(clf.fit(X, y), X, y, cv= 5)\n",
        "scores_kN.mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5964447635382181"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLfvK_bHj2wm"
      },
      "source": [
        "- Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xW4T585Fj-F2",
        "outputId": "73c7bb40-9d28-450c-9ccb-bc9d0ad2e95e"
      },
      "source": [
        "logreg = linear_model.LogisticRegression()\n",
        "logreg.fit(X,y)\n",
        "predictions_l = logreg.predict(X)\n",
        "metrics.accuracy_score(y, predictions_l)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6620488516223113"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAgLq-H03VJY",
        "outputId": "723672cb-10fe-42c4-ba0d-aa89c97b11c2"
      },
      "source": [
        "scores_log = cross_val_score(logreg.fit(X,y), X, y, cv= 5)\n",
        "scores_log.mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6569495964793319"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4wJN_3OlF9w"
      },
      "source": [
        "- Naïve Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDCWfZ5BlNC8",
        "outputId": "e3ff3a4d-ce14-400e-ea02-7b19b414a7e7"
      },
      "source": [
        "clsf_nai = naive_bayes.GaussianNB()\n",
        "clsf_nai.fit(X,y)\n",
        "predictions_n = clf.predict(X)\n",
        "metrics.accuracy_score(y, predictions_n)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7302223842508203"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6JD1B0q46Pw",
        "outputId": "0abaffd0-609e-42fd-8d0b-2c23d105cf1a"
      },
      "source": [
        "scores_nai = cross_val_score(clsf_nai.fit(X,y), X, y, cv= 5)\n",
        "scores_nai.mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5165729328706473"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDQ6WvVPlzt1"
      },
      "source": [
        "> please note that we couldn't use the multinomialNB model because there are negative values in the dataset and this returns error using the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QbQANOA5o4o"
      },
      "source": [
        "Generating a fully labelled confusion matrix for one of the classifiers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeWTRmWL5wa4"
      },
      "source": [
        "- using the K-NN classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "Bn_YJjIn52ly",
        "outputId": "f2894ce3-6531-45f4-a3a1-c2041d9b6767"
      },
      "source": [
        "cm = metrics.confusion_matrix(y, predictions_k)\n",
        "fig, ax = plt.subplots(figsize=(6,6))\n",
        "sns.heatmap(cm, ax=ax, cbar=False, annot=True, fmt='d', cmap='binary', linecolor='grey', linewidths=0.3)\n",
        "ax.set_xticklabels(['Outstanding','Good','Not Good']);\n",
        "ax.set_yticklabels(['Outstanding','Good','Not Good']);\n",
        "ax.set_xlabel('Predicted Rating')\n",
        "ax.set_ylabel('True Rating')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(30.5, 0.5, 'True Rating')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xE0mbPeHFEAQ"
      },
      "source": [
        "**Feature Engineering**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rM_36N_UFUUl"
      },
      "source": [
        "Problem with classifers not working with the Progress * feature because of the negative values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHUJ7K6sJ8ud"
      },
      "source": [
        "- while using the Naïve Bayes classifier the MultinomialNB method returned errors due to the negative values in the Progress 8 features. A simple solution to this is to perform a feature rescaling (Normalisation) which helps to put every feature in the positive range values 0 to 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1_vlR7tMbwc",
        "outputId": "a12261e5-3d65-450a-b745-588d6a967fbb"
      },
      "source": [
        "clsf_nai_m = naive_bayes.MultinomialNB()\n",
        "norm = preprocessing.MinMaxScaler()\n",
        "X_norm = norm.fit_transform(X)\n",
        "clsf_nai_m.fit(X_norm, y)\n",
        "predictions_nm = clsf_nai_m.predict(X_norm)\n",
        "metrics.accuracy_score(y, predictions_nm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5924170616113744"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHnN7xA2jErm",
        "outputId": "f0ac13e0-83dc-4dee-c8ff-9e89e98b5f0f"
      },
      "source": [
        "scores_nai = cross_val_score(clsf_nai_m.fit(X_norm, y), X_norm, y, cv= 5)\n",
        "scores_nai.mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5924175342028639"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbwZzq2kN--0"
      },
      "source": [
        "> now we have an accuracy score for this classification model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnljBTPCOH45"
      },
      "source": [
        "Applying an encoding scheme to Gender attribute"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjcKE_cGYICj"
      },
      "source": [
        "- There is the option of applying one of the two below encodings to the Gender feature\n",
        "1. Nominal Encoding\n",
        "2. Ordinal Encoding\n",
        "> Applying a **Nominal encoding** to the Gender attribute is our choice in this instance, where the categories are encoded into numbers without any ordering since there are no orders to the category of the Gender feature compared with the ordinal encoding which tends to encode in some ordering like a rank. Also this encoding makes use of less space than the original."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32-dl4XxccIH"
      },
      "source": [
        "le = preprocessing.LabelEncoder()\n",
        "ref_df['en_GENDER']=le.fit_transform(ref_df['GENDER'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srK30m_Fp_zo"
      },
      "source": [
        "Combining religious options"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z35X9lpQqDaY",
        "outputId": "a50d1f78-cb94-45f3-f64a-816714507057"
      },
      "source": [
        "ref_df['RELCHAR'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Does not apply                      1459\n",
              "None                                 826\n",
              "Roman Catholic                       262\n",
              "Church of England                    135\n",
              "Christian                             30\n",
              "Jewish                                10\n",
              "Church of England/Roman Catholic       6\n",
              "Roman Catholic/Church of England       5\n",
              "Muslim                                 5\n",
              "Sikh                                   3\n",
              "Church of England/Christian            1\n",
              "Hindu                                  1\n",
              "Name: RELCHAR, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "2Tf_9YfUq5DG",
        "outputId": "875ed62b-fdac-432c-d6bb-91bf4a1ffc9b"
      },
      "source": [
        "rel_df = ref_df[['RELCHAR']]\n",
        "rel_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RELCHAR</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Does not apply</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Does not apply</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Does not apply</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Does not apply</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Does not apply</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          RELCHAR\n",
              "0  Does not apply\n",
              "1  Does not apply\n",
              "2  Does not apply\n",
              "3  Does not apply\n",
              "4  Does not apply"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "GQLqFgHOdw3b",
        "outputId": "b4a3d8de-d495-4959-c977-0d1b7293632a"
      },
      "source": [
        "no_relig = ['Does not apply', 'None']\n",
        "rel_df['new_RELCHAR'] = [d if d in no_relig else 'religious' for d in rel_df['RELCHAR']]\n",
        "rel_df.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RELCHAR</th>\n",
              "      <th>new_RELCHAR</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Does not apply</td>\n",
              "      <td>Does not apply</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Does not apply</td>\n",
              "      <td>Does not apply</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Does not apply</td>\n",
              "      <td>Does not apply</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Does not apply</td>\n",
              "      <td>Does not apply</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Does not apply</td>\n",
              "      <td>Does not apply</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Roman Catholic</td>\n",
              "      <td>religious</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Roman Catholic</td>\n",
              "      <td>religious</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Does not apply</td>\n",
              "      <td>Does not apply</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          RELCHAR     new_RELCHAR\n",
              "0  Does not apply  Does not apply\n",
              "1  Does not apply  Does not apply\n",
              "2  Does not apply  Does not apply\n",
              "3  Does not apply  Does not apply\n",
              "4  Does not apply  Does not apply\n",
              "5            None            None\n",
              "6  Roman Catholic       religious\n",
              "7            None            None\n",
              "8  Roman Catholic       religious\n",
              "9  Does not apply  Does not apply"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "PqPSIrAMuiB_",
        "outputId": "45f413ab-1ff6-4856-f6b1-801d58d4f751"
      },
      "source": [
        "rel_df['new_RELCHAR'] = rel_df['new_RELCHAR'].replace(['Does not apply', 'None'],['non religious', 'non religious'])\n",
        "rel_df.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RELCHAR</th>\n",
              "      <th>new_RELCHAR</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Does not apply</td>\n",
              "      <td>non religious</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Does not apply</td>\n",
              "      <td>non religious</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Does not apply</td>\n",
              "      <td>non religious</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Does not apply</td>\n",
              "      <td>non religious</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Does not apply</td>\n",
              "      <td>non religious</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>None</td>\n",
              "      <td>non religious</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Roman Catholic</td>\n",
              "      <td>religious</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>None</td>\n",
              "      <td>non religious</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Roman Catholic</td>\n",
              "      <td>religious</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Does not apply</td>\n",
              "      <td>non religious</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          RELCHAR    new_RELCHAR\n",
              "0  Does not apply  non religious\n",
              "1  Does not apply  non religious\n",
              "2  Does not apply  non religious\n",
              "3  Does not apply  non religious\n",
              "4  Does not apply  non religious\n",
              "5            None  non religious\n",
              "6  Roman Catholic      religious\n",
              "7            None  non religious\n",
              "8  Roman Catholic      religious\n",
              "9  Does not apply  non religious"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "id": "jI5WlUw08DYE",
        "outputId": "032bff20-b2fe-477a-aefe-73fd4fb67798"
      },
      "source": [
        "ref_df['RELCHAR'] = rel_df['new_RELCHAR']\n",
        "ref_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>URN</th>\n",
              "      <th>LA</th>\n",
              "      <th>GENDER</th>\n",
              "      <th>RELCHAR</th>\n",
              "      <th>PNORG</th>\n",
              "      <th>PNORB</th>\n",
              "      <th>PSENELSE</th>\n",
              "      <th>PSENELK</th>\n",
              "      <th>PNUMEAL</th>\n",
              "      <th>PNUMENGFL</th>\n",
              "      <th>PNUMUNCFL</th>\n",
              "      <th>PNUMFSMEVER</th>\n",
              "      <th>PNUMFSM</th>\n",
              "      <th>PERCTOT</th>\n",
              "      <th>PPERSABS10</th>\n",
              "      <th>TPUP</th>\n",
              "      <th>P8PUP</th>\n",
              "      <th>ATT8SCR</th>\n",
              "      <th>P8MEA</th>\n",
              "      <th>P8CILOW</th>\n",
              "      <th>P8CIUPP</th>\n",
              "      <th>EBACCAPS</th>\n",
              "      <th>PTL2BASICS_94</th>\n",
              "      <th>PTL2BASICS_95</th>\n",
              "      <th>PTEBACC_E_PTQ_EE</th>\n",
              "      <th>PTEBACC_94</th>\n",
              "      <th>PTEBACC_95</th>\n",
              "      <th>PT5EM_94</th>\n",
              "      <th>P8_BANDING</th>\n",
              "      <th>OVERALL_DESTPER</th>\n",
              "      <th>NOT_SUSTAINEDPER</th>\n",
              "      <th>UNKNOWNPER</th>\n",
              "      <th>OVERALL_DESTPER_DIS</th>\n",
              "      <th>NOT_SUSTAINEDPER_DIS</th>\n",
              "      <th>UNKNOWNPER_DIS</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Rating_Val</th>\n",
              "      <th>en_GENDER</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100049</td>\n",
              "      <td>202</td>\n",
              "      <td>Mixed</td>\n",
              "      <td>non religious</td>\n",
              "      <td>41.4</td>\n",
              "      <td>58.6</td>\n",
              "      <td>3.2</td>\n",
              "      <td>11.8</td>\n",
              "      <td>73.1</td>\n",
              "      <td>26.8</td>\n",
              "      <td>0.1</td>\n",
              "      <td>64.5</td>\n",
              "      <td>41.2</td>\n",
              "      <td>6.9</td>\n",
              "      <td>18.8</td>\n",
              "      <td>199</td>\n",
              "      <td>178</td>\n",
              "      <td>42.4</td>\n",
              "      <td>-0.09</td>\n",
              "      <td>-0.28</td>\n",
              "      <td>0.09</td>\n",
              "      <td>3.72</td>\n",
              "      <td>0.588</td>\n",
              "      <td>0.432</td>\n",
              "      <td>0.241</td>\n",
              "      <td>0.191</td>\n",
              "      <td>0.141</td>\n",
              "      <td>0.533</td>\n",
              "      <td>3</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.89</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.01</td>\n",
              "      <td>Good</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100050</td>\n",
              "      <td>202</td>\n",
              "      <td>Girls</td>\n",
              "      <td>non religious</td>\n",
              "      <td>96.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.3</td>\n",
              "      <td>10.2</td>\n",
              "      <td>38.1</td>\n",
              "      <td>60.9</td>\n",
              "      <td>0.9</td>\n",
              "      <td>49.6</td>\n",
              "      <td>26.9</td>\n",
              "      <td>5.3</td>\n",
              "      <td>12.5</td>\n",
              "      <td>175</td>\n",
              "      <td>164</td>\n",
              "      <td>58.6</td>\n",
              "      <td>0.77</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.97</td>\n",
              "      <td>5.33</td>\n",
              "      <td>0.760</td>\n",
              "      <td>0.577</td>\n",
              "      <td>0.577</td>\n",
              "      <td>0.417</td>\n",
              "      <td>0.326</td>\n",
              "      <td>0.749</td>\n",
              "      <td>1</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.01</td>\n",
              "      <td>Good</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100051</td>\n",
              "      <td>202</td>\n",
              "      <td>Mixed</td>\n",
              "      <td>non religious</td>\n",
              "      <td>45.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>11.1</td>\n",
              "      <td>82.6</td>\n",
              "      <td>17.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>6.7</td>\n",
              "      <td>19.2</td>\n",
              "      <td>154</td>\n",
              "      <td>139</td>\n",
              "      <td>42.1</td>\n",
              "      <td>-0.18</td>\n",
              "      <td>-0.40</td>\n",
              "      <td>0.03</td>\n",
              "      <td>3.77</td>\n",
              "      <td>0.591</td>\n",
              "      <td>0.403</td>\n",
              "      <td>0.604</td>\n",
              "      <td>0.201</td>\n",
              "      <td>0.071</td>\n",
              "      <td>0.526</td>\n",
              "      <td>3</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.85</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.06</td>\n",
              "      <td>Good</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>100052</td>\n",
              "      <td>202</td>\n",
              "      <td>Mixed</td>\n",
              "      <td>non religious</td>\n",
              "      <td>47.5</td>\n",
              "      <td>52.5</td>\n",
              "      <td>2.4</td>\n",
              "      <td>6.9</td>\n",
              "      <td>55.8</td>\n",
              "      <td>44.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>54.2</td>\n",
              "      <td>22.8</td>\n",
              "      <td>5.4</td>\n",
              "      <td>14</td>\n",
              "      <td>200</td>\n",
              "      <td>188</td>\n",
              "      <td>44.6</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>-0.24</td>\n",
              "      <td>0.13</td>\n",
              "      <td>4.08</td>\n",
              "      <td>0.630</td>\n",
              "      <td>0.315</td>\n",
              "      <td>0.585</td>\n",
              "      <td>0.240</td>\n",
              "      <td>0.120</td>\n",
              "      <td>0.570</td>\n",
              "      <td>3</td>\n",
              "      <td>0.91</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0</td>\n",
              "      <td>Good</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>100053</td>\n",
              "      <td>202</td>\n",
              "      <td>Mixed</td>\n",
              "      <td>non religious</td>\n",
              "      <td>33.7</td>\n",
              "      <td>66.3</td>\n",
              "      <td>6.2</td>\n",
              "      <td>13.4</td>\n",
              "      <td>28.2</td>\n",
              "      <td>70.3</td>\n",
              "      <td>1.5</td>\n",
              "      <td>47.1</td>\n",
              "      <td>26.2</td>\n",
              "      <td>6.3</td>\n",
              "      <td>18.5</td>\n",
              "      <td>136</td>\n",
              "      <td>128</td>\n",
              "      <td>47.2</td>\n",
              "      <td>-0.08</td>\n",
              "      <td>-0.30</td>\n",
              "      <td>0.14</td>\n",
              "      <td>4.29</td>\n",
              "      <td>0.662</td>\n",
              "      <td>0.471</td>\n",
              "      <td>0.515</td>\n",
              "      <td>0.368</td>\n",
              "      <td>0.265</td>\n",
              "      <td>0.625</td>\n",
              "      <td>3</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.03</td>\n",
              "      <td>Good</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      URN   LA GENDER  ... Rating  Rating_Val  en_GENDER\n",
              "0  100049  202  Mixed  ...   Good           1          2\n",
              "1  100050  202  Girls  ...   Good           1          1\n",
              "2  100051  202  Mixed  ...   Good           1          2\n",
              "3  100052  202  Mixed  ...   Good           1          2\n",
              "4  100053  202  Mixed  ...   Good           1          2\n",
              "\n",
              "[5 rows x 38 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWuNfCdH89xF"
      },
      "source": [
        "It is sensible combining the religious values because already it represents a classification of schools with religious character and those without, so it is best we generalise into two distinct values no matter the type of religion practised"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S58Putr48ck_"
      },
      "source": [
        "- applying nominal encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        },
        "id": "V6ElY4Hi8iTk",
        "outputId": "c99f573a-6153-4c83-fad9-32e6a8b8cb26"
      },
      "source": [
        "la = preprocessing.LabelEncoder()\n",
        "ref_df['en_RELCHAR'] = la.fit_transform(ref_df['RELCHAR'])\n",
        "ref_df.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>URN</th>\n",
              "      <th>LA</th>\n",
              "      <th>GENDER</th>\n",
              "      <th>RELCHAR</th>\n",
              "      <th>PNORG</th>\n",
              "      <th>PNORB</th>\n",
              "      <th>PSENELSE</th>\n",
              "      <th>PSENELK</th>\n",
              "      <th>PNUMEAL</th>\n",
              "      <th>PNUMENGFL</th>\n",
              "      <th>PNUMUNCFL</th>\n",
              "      <th>PNUMFSMEVER</th>\n",
              "      <th>PNUMFSM</th>\n",
              "      <th>PERCTOT</th>\n",
              "      <th>PPERSABS10</th>\n",
              "      <th>TPUP</th>\n",
              "      <th>P8PUP</th>\n",
              "      <th>ATT8SCR</th>\n",
              "      <th>P8MEA</th>\n",
              "      <th>P8CILOW</th>\n",
              "      <th>P8CIUPP</th>\n",
              "      <th>EBACCAPS</th>\n",
              "      <th>PTL2BASICS_94</th>\n",
              "      <th>PTL2BASICS_95</th>\n",
              "      <th>PTEBACC_E_PTQ_EE</th>\n",
              "      <th>PTEBACC_94</th>\n",
              "      <th>PTEBACC_95</th>\n",
              "      <th>PT5EM_94</th>\n",
              "      <th>P8_BANDING</th>\n",
              "      <th>OVERALL_DESTPER</th>\n",
              "      <th>NOT_SUSTAINEDPER</th>\n",
              "      <th>UNKNOWNPER</th>\n",
              "      <th>OVERALL_DESTPER_DIS</th>\n",
              "      <th>NOT_SUSTAINEDPER_DIS</th>\n",
              "      <th>UNKNOWNPER_DIS</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Rating_Val</th>\n",
              "      <th>en_GENDER</th>\n",
              "      <th>en_RELCHAR</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100049</td>\n",
              "      <td>202</td>\n",
              "      <td>Mixed</td>\n",
              "      <td>non religious</td>\n",
              "      <td>41.4</td>\n",
              "      <td>58.6</td>\n",
              "      <td>3.2</td>\n",
              "      <td>11.8</td>\n",
              "      <td>73.1</td>\n",
              "      <td>26.8</td>\n",
              "      <td>0.1</td>\n",
              "      <td>64.5</td>\n",
              "      <td>41.2</td>\n",
              "      <td>6.9</td>\n",
              "      <td>18.8</td>\n",
              "      <td>199</td>\n",
              "      <td>178</td>\n",
              "      <td>42.4</td>\n",
              "      <td>-0.09</td>\n",
              "      <td>-0.28</td>\n",
              "      <td>0.09</td>\n",
              "      <td>3.72</td>\n",
              "      <td>0.588</td>\n",
              "      <td>0.432</td>\n",
              "      <td>0.241</td>\n",
              "      <td>0.191</td>\n",
              "      <td>0.141</td>\n",
              "      <td>0.533</td>\n",
              "      <td>3</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.89</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.01</td>\n",
              "      <td>Good</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100050</td>\n",
              "      <td>202</td>\n",
              "      <td>Girls</td>\n",
              "      <td>non religious</td>\n",
              "      <td>96.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.3</td>\n",
              "      <td>10.2</td>\n",
              "      <td>38.1</td>\n",
              "      <td>60.9</td>\n",
              "      <td>0.9</td>\n",
              "      <td>49.6</td>\n",
              "      <td>26.9</td>\n",
              "      <td>5.3</td>\n",
              "      <td>12.5</td>\n",
              "      <td>175</td>\n",
              "      <td>164</td>\n",
              "      <td>58.6</td>\n",
              "      <td>0.77</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.97</td>\n",
              "      <td>5.33</td>\n",
              "      <td>0.760</td>\n",
              "      <td>0.577</td>\n",
              "      <td>0.577</td>\n",
              "      <td>0.417</td>\n",
              "      <td>0.326</td>\n",
              "      <td>0.749</td>\n",
              "      <td>1</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.01</td>\n",
              "      <td>Good</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100051</td>\n",
              "      <td>202</td>\n",
              "      <td>Mixed</td>\n",
              "      <td>non religious</td>\n",
              "      <td>45.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>11.1</td>\n",
              "      <td>82.6</td>\n",
              "      <td>17.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>6.7</td>\n",
              "      <td>19.2</td>\n",
              "      <td>154</td>\n",
              "      <td>139</td>\n",
              "      <td>42.1</td>\n",
              "      <td>-0.18</td>\n",
              "      <td>-0.40</td>\n",
              "      <td>0.03</td>\n",
              "      <td>3.77</td>\n",
              "      <td>0.591</td>\n",
              "      <td>0.403</td>\n",
              "      <td>0.604</td>\n",
              "      <td>0.201</td>\n",
              "      <td>0.071</td>\n",
              "      <td>0.526</td>\n",
              "      <td>3</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.85</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.06</td>\n",
              "      <td>Good</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>100052</td>\n",
              "      <td>202</td>\n",
              "      <td>Mixed</td>\n",
              "      <td>non religious</td>\n",
              "      <td>47.5</td>\n",
              "      <td>52.5</td>\n",
              "      <td>2.4</td>\n",
              "      <td>6.9</td>\n",
              "      <td>55.8</td>\n",
              "      <td>44.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>54.2</td>\n",
              "      <td>22.8</td>\n",
              "      <td>5.4</td>\n",
              "      <td>14</td>\n",
              "      <td>200</td>\n",
              "      <td>188</td>\n",
              "      <td>44.6</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>-0.24</td>\n",
              "      <td>0.13</td>\n",
              "      <td>4.08</td>\n",
              "      <td>0.630</td>\n",
              "      <td>0.315</td>\n",
              "      <td>0.585</td>\n",
              "      <td>0.240</td>\n",
              "      <td>0.120</td>\n",
              "      <td>0.570</td>\n",
              "      <td>3</td>\n",
              "      <td>0.91</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0</td>\n",
              "      <td>Good</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>100053</td>\n",
              "      <td>202</td>\n",
              "      <td>Mixed</td>\n",
              "      <td>non religious</td>\n",
              "      <td>33.7</td>\n",
              "      <td>66.3</td>\n",
              "      <td>6.2</td>\n",
              "      <td>13.4</td>\n",
              "      <td>28.2</td>\n",
              "      <td>70.3</td>\n",
              "      <td>1.5</td>\n",
              "      <td>47.1</td>\n",
              "      <td>26.2</td>\n",
              "      <td>6.3</td>\n",
              "      <td>18.5</td>\n",
              "      <td>136</td>\n",
              "      <td>128</td>\n",
              "      <td>47.2</td>\n",
              "      <td>-0.08</td>\n",
              "      <td>-0.30</td>\n",
              "      <td>0.14</td>\n",
              "      <td>4.29</td>\n",
              "      <td>0.662</td>\n",
              "      <td>0.471</td>\n",
              "      <td>0.515</td>\n",
              "      <td>0.368</td>\n",
              "      <td>0.265</td>\n",
              "      <td>0.625</td>\n",
              "      <td>3</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.03</td>\n",
              "      <td>Good</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>100054</td>\n",
              "      <td>202</td>\n",
              "      <td>Girls</td>\n",
              "      <td>non religious</td>\n",
              "      <td>85.8</td>\n",
              "      <td>14.2</td>\n",
              "      <td>1.5</td>\n",
              "      <td>17.1</td>\n",
              "      <td>36.9</td>\n",
              "      <td>62.3</td>\n",
              "      <td>0.8</td>\n",
              "      <td>36.6</td>\n",
              "      <td>12.9</td>\n",
              "      <td>3.9</td>\n",
              "      <td>3.2</td>\n",
              "      <td>107</td>\n",
              "      <td>95</td>\n",
              "      <td>63.4</td>\n",
              "      <td>0.74</td>\n",
              "      <td>0.48</td>\n",
              "      <td>1.00</td>\n",
              "      <td>5.83</td>\n",
              "      <td>0.888</td>\n",
              "      <td>0.748</td>\n",
              "      <td>0.607</td>\n",
              "      <td>0.551</td>\n",
              "      <td>0.402</td>\n",
              "      <td>0.888</td>\n",
              "      <td>1</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.93</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.02</td>\n",
              "      <td>Outstanding</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>100055</td>\n",
              "      <td>202</td>\n",
              "      <td>Mixed</td>\n",
              "      <td>religious</td>\n",
              "      <td>58.8</td>\n",
              "      <td>41.2</td>\n",
              "      <td>3.5</td>\n",
              "      <td>8.9</td>\n",
              "      <td>52.2</td>\n",
              "      <td>47.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>54.5</td>\n",
              "      <td>29.3</td>\n",
              "      <td>5.3</td>\n",
              "      <td>14.3</td>\n",
              "      <td>115</td>\n",
              "      <td>107</td>\n",
              "      <td>48.3</td>\n",
              "      <td>0.09</td>\n",
              "      <td>-0.15</td>\n",
              "      <td>0.34</td>\n",
              "      <td>4.56</td>\n",
              "      <td>0.670</td>\n",
              "      <td>0.452</td>\n",
              "      <td>0.800</td>\n",
              "      <td>0.409</td>\n",
              "      <td>0.261</td>\n",
              "      <td>0.609</td>\n",
              "      <td>3</td>\n",
              "      <td>0.99</td>\n",
              "      <td>0</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.98</td>\n",
              "      <td>0</td>\n",
              "      <td>0.02</td>\n",
              "      <td>Good</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>100056</td>\n",
              "      <td>202</td>\n",
              "      <td>Boys</td>\n",
              "      <td>non religious</td>\n",
              "      <td>7.7</td>\n",
              "      <td>92.3</td>\n",
              "      <td>1.8</td>\n",
              "      <td>6.8</td>\n",
              "      <td>43.7</td>\n",
              "      <td>56.1</td>\n",
              "      <td>0.2</td>\n",
              "      <td>55.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>5.4</td>\n",
              "      <td>15.6</td>\n",
              "      <td>111</td>\n",
              "      <td>105</td>\n",
              "      <td>46.2</td>\n",
              "      <td>-0.44</td>\n",
              "      <td>-0.69</td>\n",
              "      <td>-0.20</td>\n",
              "      <td>4.53</td>\n",
              "      <td>0.658</td>\n",
              "      <td>0.414</td>\n",
              "      <td>0.847</td>\n",
              "      <td>0.396</td>\n",
              "      <td>0.270</td>\n",
              "      <td>0.586</td>\n",
              "      <td>4</td>\n",
              "      <td>0.93</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.93</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0</td>\n",
              "      <td>Good</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>100059</td>\n",
              "      <td>202</td>\n",
              "      <td>Girls</td>\n",
              "      <td>religious</td>\n",
              "      <td>98.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.8</td>\n",
              "      <td>8.1</td>\n",
              "      <td>43.9</td>\n",
              "      <td>56.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>42.2</td>\n",
              "      <td>17.3</td>\n",
              "      <td>4.9</td>\n",
              "      <td>9.5</td>\n",
              "      <td>173</td>\n",
              "      <td>169</td>\n",
              "      <td>54.6</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.34</td>\n",
              "      <td>0.73</td>\n",
              "      <td>4.84</td>\n",
              "      <td>0.775</td>\n",
              "      <td>0.532</td>\n",
              "      <td>0.566</td>\n",
              "      <td>0.329</td>\n",
              "      <td>0.214</td>\n",
              "      <td>0.763</td>\n",
              "      <td>1</td>\n",
              "      <td>0.97</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.99</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0</td>\n",
              "      <td>Good</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>100092</td>\n",
              "      <td>202</td>\n",
              "      <td>Mixed</td>\n",
              "      <td>non religious</td>\n",
              "      <td>11.8</td>\n",
              "      <td>88.2</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.6</td>\n",
              "      <td>79.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>91.2</td>\n",
              "      <td>67.6</td>\n",
              "      <td>27.9</td>\n",
              "      <td>81.4</td>\n",
              "      <td>17</td>\n",
              "      <td>16</td>\n",
              "      <td>3.4</td>\n",
              "      <td>-2.98</td>\n",
              "      <td>-3.60</td>\n",
              "      <td>-2.35</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.059</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>5</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.13</td>\n",
              "      <td>SUPP</td>\n",
              "      <td>SUPP</td>\n",
              "      <td>SUPP</td>\n",
              "      <td>Good</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      URN   LA GENDER  ... Rating_Val  en_GENDER  en_RELCHAR\n",
              "0  100049  202  Mixed  ...          1          2           0\n",
              "1  100050  202  Girls  ...          1          1           0\n",
              "2  100051  202  Mixed  ...          1          2           0\n",
              "3  100052  202  Mixed  ...          1          2           0\n",
              "4  100053  202  Mixed  ...          1          2           0\n",
              "5  100054  202  Girls  ...          2          1           0\n",
              "6  100055  202  Mixed  ...          1          2           1\n",
              "7  100056  202   Boys  ...          1          0           0\n",
              "8  100059  202  Girls  ...          1          1           1\n",
              "9  100092  202  Mixed  ...          1          2           0\n",
              "\n",
              "[10 rows x 39 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YUhMxj88s3V"
      },
      "source": [
        "Estimating accuracy of classifiers with new features (GENDER and RELCHAR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVCHqIks9rv8"
      },
      "source": [
        "- K-NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "va44nWoI9nzd",
        "outputId": "9ffb5a60-2920-4599-ee5f-2de880ecd2de"
      },
      "source": [
        "X_new = ref_df[['en_GENDER','en_RELCHAR','PNORG','PNORB','PSENELSE','PSENELK','PNUMEAL','PNUMENGFL','PNUMUNCFL','PNUMFSM','P8PUP','ATT8SCR','P8MEA']].values\n",
        "y = ref_df['Rating_Val'].values\n",
        "kn_clf = neighbors.KNeighborsClassifier()\n",
        "kn_clf.fit(X_new,y)\n",
        "predictions_kn = kn_clf.predict(X_new)\n",
        "metrics.accuracy_score(y, predictions_kn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7291286912139993"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kkc7oQAyjmLJ",
        "outputId": "7ed23363-20aa-474a-e588-831c9f715170"
      },
      "source": [
        "scores_kN = cross_val_score(kn_clf.fit(X_new,y), X_new, y, cv= 5)\n",
        "scores_kN.mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5975389892704719"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGtTCSyQCE29"
      },
      "source": [
        "- Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogHsxJxxCHNV",
        "outputId": "3a60a216-4d63-4277-cd6c-cbe1c1012f86"
      },
      "source": [
        "log_clf = linear_model.LogisticRegression()\n",
        "log_clf.fit(X_new,y)\n",
        "predictions_lg = log_clf.predict(X_new)\n",
        "metrics.accuracy_score(y, predictions_lg)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6613197229310973"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bU8ly5aFj7sf",
        "outputId": "b3ac76ba-4a32-4d07-fd70-2da36a31a3b6"
      },
      "source": [
        "scores_log = cross_val_score(log_clf.fit(X_new,y), X_new, y, cv= 5)\n",
        "scores_log.mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6562190046933376"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2Qk4FTqD-gb"
      },
      "source": [
        "- Naïve Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hAAKxHfD_tW",
        "outputId": "1a4f4505-6336-4423-ba4e-3a76d4c431aa"
      },
      "source": [
        "na_clf = naive_bayes.GaussianNB()\n",
        "na_clf.fit(X_new,y)\n",
        "predictions_na = na_clf.predict(X_new)\n",
        "metrics.accuracy_score(y, predictions_na)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5154939846882974"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Cr7wzyPkHZK",
        "outputId": "93e650b7-cee7-4db6-9b0d-e2920f7b168e"
      },
      "source": [
        "scores_nai = cross_val_score(na_clf.fit(X_new,y), X_new, y, cv= 5)\n",
        "scores_nai.mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.49724183319372983"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-ircY-uEzs0"
      },
      "source": [
        "Handling features with a mix of numeric and non-numeric values\n",
        "- Earlier in the previous components (component two), these features which contained a mix of numeric and non-numeric values (SUPP and SP) were temporary handled by replacing the non-numeric values with a specific numeric value for visualization of distribution. The features which contains this mix are (P8_BANDING, OVERALL_DESTPER, NOT_SUSTAINEDPER,UNKNOWNPER, OVERALL_DESTPER_DIS,\tNOT_SUSTAINEDPER_DIS, UNKNOWNPER_DIS)\n",
        "> A method for making these features usable by the classifiers is if these non-numeric values are replaced with numeric values. These non-numeric values SUPP and SP are used to represent suppressed data and small percentage less than 0.5 respectively. Since the required value are supposed to range from 0 to 1 and considering the initial condition for using these representations in the first place, taking the average value which is 0.5 to replace these values is the method to go with."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "id": "NjbAp2b2RW8i",
        "outputId": "bae43f71-a835-474d-f9f7-1ae3ef3315c0"
      },
      "source": [
        "final_df = ref_df.replace(['SUPP', 'SP'],[0.5,0.5])\n",
        "final_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>URN</th>\n",
              "      <th>LA</th>\n",
              "      <th>GENDER</th>\n",
              "      <th>RELCHAR</th>\n",
              "      <th>PNORG</th>\n",
              "      <th>PNORB</th>\n",
              "      <th>PSENELSE</th>\n",
              "      <th>PSENELK</th>\n",
              "      <th>PNUMEAL</th>\n",
              "      <th>PNUMENGFL</th>\n",
              "      <th>PNUMUNCFL</th>\n",
              "      <th>PNUMFSMEVER</th>\n",
              "      <th>PNUMFSM</th>\n",
              "      <th>PERCTOT</th>\n",
              "      <th>PPERSABS10</th>\n",
              "      <th>TPUP</th>\n",
              "      <th>P8PUP</th>\n",
              "      <th>ATT8SCR</th>\n",
              "      <th>P8MEA</th>\n",
              "      <th>P8CILOW</th>\n",
              "      <th>P8CIUPP</th>\n",
              "      <th>EBACCAPS</th>\n",
              "      <th>PTL2BASICS_94</th>\n",
              "      <th>PTL2BASICS_95</th>\n",
              "      <th>PTEBACC_E_PTQ_EE</th>\n",
              "      <th>PTEBACC_94</th>\n",
              "      <th>PTEBACC_95</th>\n",
              "      <th>PT5EM_94</th>\n",
              "      <th>P8_BANDING</th>\n",
              "      <th>OVERALL_DESTPER</th>\n",
              "      <th>NOT_SUSTAINEDPER</th>\n",
              "      <th>UNKNOWNPER</th>\n",
              "      <th>OVERALL_DESTPER_DIS</th>\n",
              "      <th>NOT_SUSTAINEDPER_DIS</th>\n",
              "      <th>UNKNOWNPER_DIS</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Rating_Val</th>\n",
              "      <th>en_GENDER</th>\n",
              "      <th>en_RELCHAR</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100049</td>\n",
              "      <td>202</td>\n",
              "      <td>Mixed</td>\n",
              "      <td>non religious</td>\n",
              "      <td>41.4</td>\n",
              "      <td>58.6</td>\n",
              "      <td>3.2</td>\n",
              "      <td>11.8</td>\n",
              "      <td>73.1</td>\n",
              "      <td>26.8</td>\n",
              "      <td>0.1</td>\n",
              "      <td>64.5</td>\n",
              "      <td>41.2</td>\n",
              "      <td>6.9</td>\n",
              "      <td>18.8</td>\n",
              "      <td>199</td>\n",
              "      <td>178</td>\n",
              "      <td>42.4</td>\n",
              "      <td>-0.09</td>\n",
              "      <td>-0.28</td>\n",
              "      <td>0.09</td>\n",
              "      <td>3.72</td>\n",
              "      <td>0.588</td>\n",
              "      <td>0.432</td>\n",
              "      <td>0.241</td>\n",
              "      <td>0.191</td>\n",
              "      <td>0.141</td>\n",
              "      <td>0.533</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.89</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.01</td>\n",
              "      <td>Good</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100050</td>\n",
              "      <td>202</td>\n",
              "      <td>Girls</td>\n",
              "      <td>non religious</td>\n",
              "      <td>96.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.3</td>\n",
              "      <td>10.2</td>\n",
              "      <td>38.1</td>\n",
              "      <td>60.9</td>\n",
              "      <td>0.9</td>\n",
              "      <td>49.6</td>\n",
              "      <td>26.9</td>\n",
              "      <td>5.3</td>\n",
              "      <td>12.5</td>\n",
              "      <td>175</td>\n",
              "      <td>164</td>\n",
              "      <td>58.6</td>\n",
              "      <td>0.77</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.97</td>\n",
              "      <td>5.33</td>\n",
              "      <td>0.760</td>\n",
              "      <td>0.577</td>\n",
              "      <td>0.577</td>\n",
              "      <td>0.417</td>\n",
              "      <td>0.326</td>\n",
              "      <td>0.749</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.01</td>\n",
              "      <td>Good</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100051</td>\n",
              "      <td>202</td>\n",
              "      <td>Mixed</td>\n",
              "      <td>non religious</td>\n",
              "      <td>45.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>11.1</td>\n",
              "      <td>82.6</td>\n",
              "      <td>17.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>6.7</td>\n",
              "      <td>19.2</td>\n",
              "      <td>154</td>\n",
              "      <td>139</td>\n",
              "      <td>42.1</td>\n",
              "      <td>-0.18</td>\n",
              "      <td>-0.40</td>\n",
              "      <td>0.03</td>\n",
              "      <td>3.77</td>\n",
              "      <td>0.591</td>\n",
              "      <td>0.403</td>\n",
              "      <td>0.604</td>\n",
              "      <td>0.201</td>\n",
              "      <td>0.071</td>\n",
              "      <td>0.526</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.85</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.06</td>\n",
              "      <td>Good</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>100052</td>\n",
              "      <td>202</td>\n",
              "      <td>Mixed</td>\n",
              "      <td>non religious</td>\n",
              "      <td>47.5</td>\n",
              "      <td>52.5</td>\n",
              "      <td>2.4</td>\n",
              "      <td>6.9</td>\n",
              "      <td>55.8</td>\n",
              "      <td>44.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>54.2</td>\n",
              "      <td>22.8</td>\n",
              "      <td>5.4</td>\n",
              "      <td>14.0</td>\n",
              "      <td>200</td>\n",
              "      <td>188</td>\n",
              "      <td>44.6</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>-0.24</td>\n",
              "      <td>0.13</td>\n",
              "      <td>4.08</td>\n",
              "      <td>0.630</td>\n",
              "      <td>0.315</td>\n",
              "      <td>0.585</td>\n",
              "      <td>0.240</td>\n",
              "      <td>0.120</td>\n",
              "      <td>0.570</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.91</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.00</td>\n",
              "      <td>Good</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>100053</td>\n",
              "      <td>202</td>\n",
              "      <td>Mixed</td>\n",
              "      <td>non religious</td>\n",
              "      <td>33.7</td>\n",
              "      <td>66.3</td>\n",
              "      <td>6.2</td>\n",
              "      <td>13.4</td>\n",
              "      <td>28.2</td>\n",
              "      <td>70.3</td>\n",
              "      <td>1.5</td>\n",
              "      <td>47.1</td>\n",
              "      <td>26.2</td>\n",
              "      <td>6.3</td>\n",
              "      <td>18.5</td>\n",
              "      <td>136</td>\n",
              "      <td>128</td>\n",
              "      <td>47.2</td>\n",
              "      <td>-0.08</td>\n",
              "      <td>-0.30</td>\n",
              "      <td>0.14</td>\n",
              "      <td>4.29</td>\n",
              "      <td>0.662</td>\n",
              "      <td>0.471</td>\n",
              "      <td>0.515</td>\n",
              "      <td>0.368</td>\n",
              "      <td>0.265</td>\n",
              "      <td>0.625</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.03</td>\n",
              "      <td>Good</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      URN   LA GENDER        RELCHAR  ...  Rating  Rating_Val  en_GENDER  en_RELCHAR\n",
              "0  100049  202  Mixed  non religious  ...    Good           1          2           0\n",
              "1  100050  202  Girls  non religious  ...    Good           1          1           0\n",
              "2  100051  202  Mixed  non religious  ...    Good           1          2           0\n",
              "3  100052  202  Mixed  non religious  ...    Good           1          2           0\n",
              "4  100053  202  Mixed  non religious  ...    Good           1          2           0\n",
              "\n",
              "[5 rows x 39 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sX1tRJY0tKrU"
      },
      "source": [
        "- classifier accuracy with these features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bDPzMAatfL1"
      },
      "source": [
        "- K-NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tR-ElC_AtOrN",
        "outputId": "f831afd9-386f-4ee2-8588-27ffcb5a3c41"
      },
      "source": [
        "X_n = final_df[['en_GENDER','en_RELCHAR','PNORG','PNORB','PSENELSE','PSENELK','PNUMEAL','PNUMENGFL','PNUMUNCFL','PNUMFSM','P8PUP','ATT8SCR','P8MEA','P8_BANDING', 'OVERALL_DESTPER', 'NOT_SUSTAINEDPER','UNKNOWNPER']].values\n",
        "y = final_df['Rating_Val'].values\n",
        "kn_clf = neighbors.KNeighborsClassifier()\n",
        "kn_clf.fit(X_n,y)\n",
        "predictions_kn = kn_clf.predict(X_n)\n",
        "metrics.accuracy_score(y, predictions_kn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7298578199052133"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13vqyKe_kWiV",
        "outputId": "53e4d119-f28a-4a00-8c7f-201e8817055a"
      },
      "source": [
        "scores_kN = cross_val_score(kn_clf.fit(X_n,y), X_n, y, cv= 5)\n",
        "scores_kN.mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5979046175528167"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_yt40vluMir"
      },
      "source": [
        "- Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8aCGhEfvS6v",
        "outputId": "faa83713-bc04-4089-9b07-c275b3a02645"
      },
      "source": [
        "log_clf = linear_model.LogisticRegression()\n",
        "log_clf.fit(X_n,y)\n",
        "predictions_lg = log_clf.predict(X_n)\n",
        "metrics.accuracy_score(y, predictions_lg)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6678818811520233"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZqmoyikkmxc",
        "outputId": "10bf033d-9b78-49bd-8141-45bd0356c688"
      },
      "source": [
        "scores_log = cross_val_score(log_clf.fit(X_n,y), X_n, y, cv= 5)\n",
        "scores_log.mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6605925837288767"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6EdCzCAvirV"
      },
      "source": [
        "- Naïve Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7p5xkublvmWj",
        "outputId": "514cf467-d734-4ba6-e513-645ee21fd986"
      },
      "source": [
        "na_clf = naive_bayes.GaussianNB()\n",
        "na_clf.fit(X_n,y)\n",
        "predictions_na = na_clf.predict(X_n)\n",
        "metrics.accuracy_score(y, predictions_na)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5446591323368575"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vF8QWnwk1Dx",
        "outputId": "465fc979-bd65-4016-ad7e-f240361e05e3"
      },
      "source": [
        "scores_nai = cross_val_score(na_clf.fit(X_n,y), X_n, y, cv= 5)\n",
        "scores_nai.mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5260466940555488"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMdtFa1nEBrW"
      },
      "source": [
        "Applying Standardisation and Normalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgMg_FHAEKOc"
      },
      "source": [
        "- Standardisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXVVRuHNEN9z",
        "outputId": "4e3e39d9-a4fa-40df-910e-1c061cf08f0b"
      },
      "source": [
        "# K-NN\n",
        "scaler = preprocessing.StandardScaler()\n",
        "X_sc = scaler.fit_transform(X_n)\n",
        "y = final_df['Rating_Val'].values\n",
        "kn_clf = neighbors.KNeighborsClassifier()\n",
        "kn_clf.fit(X_sc,y)\n",
        "predictions_kn = kn_clf.predict(X_sc)\n",
        "metrics.accuracy_score(y, predictions_kn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7513671162960263"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VeF3bOfslDI2",
        "outputId": "bb410b98-d1e7-4102-db39-3f637dc07673"
      },
      "source": [
        "scores_kN = cross_val_score(kn_clf.fit(X_sc,y), X_sc, y, cv= 5)\n",
        "scores_kN.mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6146537167776847"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3r0DdFJH0Lf",
        "outputId": "54c26bd1-1b55-448c-d637-57c348e7cfce"
      },
      "source": [
        "# Logistic Regression\n",
        "log_clf = linear_model.LogisticRegression()\n",
        "log_clf.fit(X_sc,y)\n",
        "predictions_lg = log_clf.predict(X_sc)\n",
        "metrics.accuracy_score(y, predictions_lg)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6766314254465913"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c0sb9UdlUfk",
        "outputId": "1715011e-2edb-4e5c-a9ec-227f6dd15e18"
      },
      "source": [
        "scores_log = cross_val_score(log_clf.fit(X_sc,y), X_sc, y, cv= 5)\n",
        "scores_log.mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6649781287809289"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWC9hvhKIGqd",
        "outputId": "f390b3d9-fb3c-416a-c76d-d6f376dcc763"
      },
      "source": [
        "# Naive Bayes\n",
        "na_clf = naive_bayes.GaussianNB()\n",
        "na_clf.fit(X_sc,y)\n",
        "predictions_na = na_clf.predict(X_sc)\n",
        "metrics.accuracy_score(y, predictions_na)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5446591323368575"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEYoOb2zljct",
        "outputId": "ab220f89-a4b3-402e-ad94-e75150ee3a6c"
      },
      "source": [
        "scores_nai = cross_val_score(na_clf.fit(X_sc,y), X_sc, y, cv= 5)\n",
        "scores_nai.mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5260466940555488"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BuSr7rnIcMx"
      },
      "source": [
        "- Normalisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWNupzQpIfMb",
        "outputId": "4b98e87c-54af-432d-8ac8-450bf98763fd"
      },
      "source": [
        "# K-NN\n",
        "norm = preprocessing.MinMaxScaler()\n",
        "X_nm = norm.fit_transform(X_n)\n",
        "y = final_df['Rating_Val'].values\n",
        "kn_clf = neighbors.KNeighborsClassifier()\n",
        "kn_clf.fit(X_nm,y)\n",
        "predictions_kn = kn_clf.predict(X_nm)\n",
        "metrics.accuracy_score(y, predictions_kn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7448049580751003"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIF9_yQAl4hS",
        "outputId": "37a57eac-b351-40aa-9a67-d6920e124a35"
      },
      "source": [
        "scores_kN = cross_val_score(kn_clf.fit(X_nm,y), X_nm, y, cv= 5)\n",
        "scores_kN.mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6204851554917369"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vec5Q3IGJOkD",
        "outputId": "96e63560-3158-458c-cdb5-8487bbfb4b74"
      },
      "source": [
        "# Logistic Regression\n",
        "log_clf = linear_model.LogisticRegression()\n",
        "log_clf.fit(X_nm,y)\n",
        "predictions_lg = log_clf.predict(X_nm)\n",
        "metrics.accuracy_score(y, predictions_lg)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6784542471746263"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X72TrUksmUa4",
        "outputId": "59c16ae5-2d9f-42f2-fb69-80321f6275e1"
      },
      "source": [
        "scores_log = cross_val_score(log_clf.fit(X_nm,y), X_nm, y, cv= 5)\n",
        "scores_log.mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6715328467153285"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rMRSyjyJdlI",
        "outputId": "fced9241-f445-4d11-dba5-84f18c1f0503"
      },
      "source": [
        "# Naive Bayes\n",
        "na_clf = naive_bayes.GaussianNB()\n",
        "na_clf.fit(X_nm,y)\n",
        "predictions_na = na_clf.predict(X_nm)\n",
        "metrics.accuracy_score(y, predictions_na)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5446591323368575"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LCRzogbmdGX",
        "outputId": "b2840c5e-d211-43fc-faba-8ae3ca95aba6"
      },
      "source": [
        "scores_nai = cross_val_score(na_clf.fit(X_nm,y), X_nm, y, cv= 5)\n",
        "scores_nai.mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5260466940555488"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpHFwG0vJmd2"
      },
      "source": [
        "Other Feature engineering approach to increase accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_PxjSQlJzEF"
      },
      "source": [
        "1. Binarisation\n",
        "  - The PNUMUNCFL feature which records pupils whose first language are unclassified contains lots of zero values which means at this point where zero is recorded every student is classified , therefore Binarisation can be performed on this feature to create a new feature that indicates if the pupils first language are all classified or not (FILCLF)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "id": "joHxGYI2gqXF",
        "outputId": "2c4d40ce-d6b7-4302-d131-0f72e5ea8142"
      },
      "source": [
        "b = preprocessing.Binarizer(threshold=0)\n",
        "final_df['FILCLF'] =  b.fit_transform(final_df['PNUMUNCFL'].values.reshape(-1,1))\n",
        "final_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>URN</th>\n",
              "      <th>LA</th>\n",
              "      <th>GENDER</th>\n",
              "      <th>RELCHAR</th>\n",
              "      <th>PNORG</th>\n",
              "      <th>PNORB</th>\n",
              "      <th>PSENELSE</th>\n",
              "      <th>PSENELK</th>\n",
              "      <th>PNUMEAL</th>\n",
              "      <th>PNUMENGFL</th>\n",
              "      <th>PNUMUNCFL</th>\n",
              "      <th>PNUMFSMEVER</th>\n",
              "      <th>PNUMFSM</th>\n",
              "      <th>PERCTOT</th>\n",
              "      <th>PPERSABS10</th>\n",
              "      <th>TPUP</th>\n",
              "      <th>P8PUP</th>\n",
              "      <th>ATT8SCR</th>\n",
              "      <th>P8MEA</th>\n",
              "      <th>P8CILOW</th>\n",
              "      <th>P8CIUPP</th>\n",
              "      <th>EBACCAPS</th>\n",
              "      <th>PTL2BASICS_94</th>\n",
              "      <th>PTL2BASICS_95</th>\n",
              "      <th>PTEBACC_E_PTQ_EE</th>\n",
              "      <th>PTEBACC_94</th>\n",
              "      <th>PTEBACC_95</th>\n",
              "      <th>PT5EM_94</th>\n",
              "      <th>P8_BANDING</th>\n",
              "      <th>OVERALL_DESTPER</th>\n",
              "      <th>NOT_SUSTAINEDPER</th>\n",
              "      <th>UNKNOWNPER</th>\n",
              "      <th>OVERALL_DESTPER_DIS</th>\n",
              "      <th>NOT_SUSTAINEDPER_DIS</th>\n",
              "      <th>UNKNOWNPER_DIS</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Rating_Val</th>\n",
              "      <th>en_GENDER</th>\n",
              "      <th>en_RELCHAR</th>\n",
              "      <th>FILCLF</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100049</td>\n",
              "      <td>202</td>\n",
              "      <td>Mixed</td>\n",
              "      <td>non religious</td>\n",
              "      <td>41.4</td>\n",
              "      <td>58.6</td>\n",
              "      <td>3.2</td>\n",
              "      <td>11.8</td>\n",
              "      <td>73.1</td>\n",
              "      <td>26.8</td>\n",
              "      <td>0.1</td>\n",
              "      <td>64.5</td>\n",
              "      <td>41.2</td>\n",
              "      <td>6.9</td>\n",
              "      <td>18.8</td>\n",
              "      <td>199</td>\n",
              "      <td>178</td>\n",
              "      <td>42.4</td>\n",
              "      <td>-0.09</td>\n",
              "      <td>-0.28</td>\n",
              "      <td>0.09</td>\n",
              "      <td>3.72</td>\n",
              "      <td>0.588</td>\n",
              "      <td>0.432</td>\n",
              "      <td>0.241</td>\n",
              "      <td>0.191</td>\n",
              "      <td>0.141</td>\n",
              "      <td>0.533</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.89</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.01</td>\n",
              "      <td>Good</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100050</td>\n",
              "      <td>202</td>\n",
              "      <td>Girls</td>\n",
              "      <td>non religious</td>\n",
              "      <td>96.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.3</td>\n",
              "      <td>10.2</td>\n",
              "      <td>38.1</td>\n",
              "      <td>60.9</td>\n",
              "      <td>0.9</td>\n",
              "      <td>49.6</td>\n",
              "      <td>26.9</td>\n",
              "      <td>5.3</td>\n",
              "      <td>12.5</td>\n",
              "      <td>175</td>\n",
              "      <td>164</td>\n",
              "      <td>58.6</td>\n",
              "      <td>0.77</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.97</td>\n",
              "      <td>5.33</td>\n",
              "      <td>0.760</td>\n",
              "      <td>0.577</td>\n",
              "      <td>0.577</td>\n",
              "      <td>0.417</td>\n",
              "      <td>0.326</td>\n",
              "      <td>0.749</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.01</td>\n",
              "      <td>Good</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100051</td>\n",
              "      <td>202</td>\n",
              "      <td>Mixed</td>\n",
              "      <td>non religious</td>\n",
              "      <td>45.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>11.1</td>\n",
              "      <td>82.6</td>\n",
              "      <td>17.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>6.7</td>\n",
              "      <td>19.2</td>\n",
              "      <td>154</td>\n",
              "      <td>139</td>\n",
              "      <td>42.1</td>\n",
              "      <td>-0.18</td>\n",
              "      <td>-0.40</td>\n",
              "      <td>0.03</td>\n",
              "      <td>3.77</td>\n",
              "      <td>0.591</td>\n",
              "      <td>0.403</td>\n",
              "      <td>0.604</td>\n",
              "      <td>0.201</td>\n",
              "      <td>0.071</td>\n",
              "      <td>0.526</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.85</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.06</td>\n",
              "      <td>Good</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>100052</td>\n",
              "      <td>202</td>\n",
              "      <td>Mixed</td>\n",
              "      <td>non religious</td>\n",
              "      <td>47.5</td>\n",
              "      <td>52.5</td>\n",
              "      <td>2.4</td>\n",
              "      <td>6.9</td>\n",
              "      <td>55.8</td>\n",
              "      <td>44.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>54.2</td>\n",
              "      <td>22.8</td>\n",
              "      <td>5.4</td>\n",
              "      <td>14.0</td>\n",
              "      <td>200</td>\n",
              "      <td>188</td>\n",
              "      <td>44.6</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>-0.24</td>\n",
              "      <td>0.13</td>\n",
              "      <td>4.08</td>\n",
              "      <td>0.630</td>\n",
              "      <td>0.315</td>\n",
              "      <td>0.585</td>\n",
              "      <td>0.240</td>\n",
              "      <td>0.120</td>\n",
              "      <td>0.570</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.91</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.00</td>\n",
              "      <td>Good</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>100053</td>\n",
              "      <td>202</td>\n",
              "      <td>Mixed</td>\n",
              "      <td>non religious</td>\n",
              "      <td>33.7</td>\n",
              "      <td>66.3</td>\n",
              "      <td>6.2</td>\n",
              "      <td>13.4</td>\n",
              "      <td>28.2</td>\n",
              "      <td>70.3</td>\n",
              "      <td>1.5</td>\n",
              "      <td>47.1</td>\n",
              "      <td>26.2</td>\n",
              "      <td>6.3</td>\n",
              "      <td>18.5</td>\n",
              "      <td>136</td>\n",
              "      <td>128</td>\n",
              "      <td>47.2</td>\n",
              "      <td>-0.08</td>\n",
              "      <td>-0.30</td>\n",
              "      <td>0.14</td>\n",
              "      <td>4.29</td>\n",
              "      <td>0.662</td>\n",
              "      <td>0.471</td>\n",
              "      <td>0.515</td>\n",
              "      <td>0.368</td>\n",
              "      <td>0.265</td>\n",
              "      <td>0.625</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.03</td>\n",
              "      <td>Good</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      URN   LA GENDER        RELCHAR  ...  Rating_Val  en_GENDER  en_RELCHAR  FILCLF\n",
              "0  100049  202  Mixed  non religious  ...           1          2           0     1.0\n",
              "1  100050  202  Girls  non religious  ...           1          1           0     1.0\n",
              "2  100051  202  Mixed  non religious  ...           1          2           0     0.0\n",
              "3  100052  202  Mixed  non religious  ...           1          2           0     0.0\n",
              "4  100053  202  Mixed  non religious  ...           1          2           0     1.0\n",
              "\n",
              "[5 rows x 40 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfvFS-Wdkhu3",
        "outputId": "7e352198-7a84-4f83-bc4c-237805cbfd11"
      },
      "source": [
        "# K-NN\n",
        "new_X = final_df[['FILCLF','en_GENDER','en_RELCHAR','PNORG','PNORB','PSENELSE','PSENELK','PNUMEAL','PNUMENGFL','PNUMFSM','P8PUP','ATT8SCR','P8MEA','P8_BANDING', 'OVERALL_DESTPER', 'NOT_SUSTAINEDPER','UNKNOWNPER']].values\n",
        "y = final_df['Rating_Val'].values\n",
        "kn_clf = neighbors.KNeighborsClassifier()\n",
        "kn_clf.fit(new_X,y)\n",
        "predictions_kn = kn_clf.predict(new_X)\n",
        "metrics.accuracy_score(y, predictions_kn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7309515129420343"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kjv370-QmpKg",
        "outputId": "25bacc74-cd0b-4adf-a01b-a9b2135cd6bd"
      },
      "source": [
        "scores_kN = cross_val_score(kn_clf.fit(new_X,y), new_X, y, cv= 5)\n",
        "scores_kN.mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5982702458351615"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-fOcb-Eo3pZ"
      },
      "source": [
        "2. Log Transformation:\n",
        "  - This feature engineering approach is used to compress higher values or values skewed to a side, in order to lead to a more normal distribution.\n",
        "  we will try to apply this approach to the P8PUP feature which appears to be skewed to the left."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "PS453zEQtL1Y",
        "outputId": "946b0784-f62c-407a-dae1-fa5279c4fcae"
      },
      "source": [
        "sns.distplot(final_df['P8PUP'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seaborn/distributions.py:2551: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f66a88d1f28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "id": "Hn0NQJXRq_xz",
        "outputId": "09983bb9-f502-49c8-8116-3c98cc7a6231"
      },
      "source": [
        "final_df['P8PUP_log'] = final_df['P8PUP'].apply(np.log10)\n",
        "final_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>URN</th>\n",
              "      <th>LA</th>\n",
              "      <th>GENDER</th>\n",
              "      <th>RELCHAR</th>\n",
              "      <th>PNORG</th>\n",
              "      <th>PNORB</th>\n",
              "      <th>PSENELSE</th>\n",
              "      <th>PSENELK</th>\n",
              "      <th>PNUMEAL</th>\n",
              "      <th>PNUMENGFL</th>\n",
              "      <th>PNUMUNCFL</th>\n",
              "      <th>PNUMFSMEVER</th>\n",
              "      <th>PNUMFSM</th>\n",
              "      <th>PERCTOT</th>\n",
              "      <th>PPERSABS10</th>\n",
              "      <th>TPUP</th>\n",
              "      <th>P8PUP</th>\n",
              "      <th>ATT8SCR</th>\n",
              "      <th>P8MEA</th>\n",
              "      <th>P8CILOW</th>\n",
              "      <th>P8CIUPP</th>\n",
              "      <th>EBACCAPS</th>\n",
              "      <th>PTL2BASICS_94</th>\n",
              "      <th>PTL2BASICS_95</th>\n",
              "      <th>PTEBACC_E_PTQ_EE</th>\n",
              "      <th>PTEBACC_94</th>\n",
              "      <th>PTEBACC_95</th>\n",
              "      <th>PT5EM_94</th>\n",
              "      <th>P8_BANDING</th>\n",
              "      <th>OVERALL_DESTPER</th>\n",
              "      <th>NOT_SUSTAINEDPER</th>\n",
              "      <th>UNKNOWNPER</th>\n",
              "      <th>OVERALL_DESTPER_DIS</th>\n",
              "      <th>NOT_SUSTAINEDPER_DIS</th>\n",
              "      <th>UNKNOWNPER_DIS</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Rating_Val</th>\n",
              "      <th>en_GENDER</th>\n",
              "      <th>en_RELCHAR</th>\n",
              "      <th>FILCLF</th>\n",
              "      <th>P8PUP_log</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100049</td>\n",
              "      <td>202</td>\n",
              "      <td>Mixed</td>\n",
              "      <td>non religious</td>\n",
              "      <td>41.4</td>\n",
              "      <td>58.6</td>\n",
              "      <td>3.2</td>\n",
              "      <td>11.8</td>\n",
              "      <td>73.1</td>\n",
              "      <td>26.8</td>\n",
              "      <td>0.1</td>\n",
              "      <td>64.5</td>\n",
              "      <td>41.2</td>\n",
              "      <td>6.9</td>\n",
              "      <td>18.8</td>\n",
              "      <td>199</td>\n",
              "      <td>178</td>\n",
              "      <td>42.4</td>\n",
              "      <td>-0.09</td>\n",
              "      <td>-0.28</td>\n",
              "      <td>0.09</td>\n",
              "      <td>3.72</td>\n",
              "      <td>0.588</td>\n",
              "      <td>0.432</td>\n",
              "      <td>0.241</td>\n",
              "      <td>0.191</td>\n",
              "      <td>0.141</td>\n",
              "      <td>0.533</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.89</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.01</td>\n",
              "      <td>Good</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.250420</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100050</td>\n",
              "      <td>202</td>\n",
              "      <td>Girls</td>\n",
              "      <td>non religious</td>\n",
              "      <td>96.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.3</td>\n",
              "      <td>10.2</td>\n",
              "      <td>38.1</td>\n",
              "      <td>60.9</td>\n",
              "      <td>0.9</td>\n",
              "      <td>49.6</td>\n",
              "      <td>26.9</td>\n",
              "      <td>5.3</td>\n",
              "      <td>12.5</td>\n",
              "      <td>175</td>\n",
              "      <td>164</td>\n",
              "      <td>58.6</td>\n",
              "      <td>0.77</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.97</td>\n",
              "      <td>5.33</td>\n",
              "      <td>0.760</td>\n",
              "      <td>0.577</td>\n",
              "      <td>0.577</td>\n",
              "      <td>0.417</td>\n",
              "      <td>0.326</td>\n",
              "      <td>0.749</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.01</td>\n",
              "      <td>Good</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.214844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100051</td>\n",
              "      <td>202</td>\n",
              "      <td>Mixed</td>\n",
              "      <td>non religious</td>\n",
              "      <td>45.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>11.1</td>\n",
              "      <td>82.6</td>\n",
              "      <td>17.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>6.7</td>\n",
              "      <td>19.2</td>\n",
              "      <td>154</td>\n",
              "      <td>139</td>\n",
              "      <td>42.1</td>\n",
              "      <td>-0.18</td>\n",
              "      <td>-0.40</td>\n",
              "      <td>0.03</td>\n",
              "      <td>3.77</td>\n",
              "      <td>0.591</td>\n",
              "      <td>0.403</td>\n",
              "      <td>0.604</td>\n",
              "      <td>0.201</td>\n",
              "      <td>0.071</td>\n",
              "      <td>0.526</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.85</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.06</td>\n",
              "      <td>Good</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.143015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>100052</td>\n",
              "      <td>202</td>\n",
              "      <td>Mixed</td>\n",
              "      <td>non religious</td>\n",
              "      <td>47.5</td>\n",
              "      <td>52.5</td>\n",
              "      <td>2.4</td>\n",
              "      <td>6.9</td>\n",
              "      <td>55.8</td>\n",
              "      <td>44.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>54.2</td>\n",
              "      <td>22.8</td>\n",
              "      <td>5.4</td>\n",
              "      <td>14.0</td>\n",
              "      <td>200</td>\n",
              "      <td>188</td>\n",
              "      <td>44.6</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>-0.24</td>\n",
              "      <td>0.13</td>\n",
              "      <td>4.08</td>\n",
              "      <td>0.630</td>\n",
              "      <td>0.315</td>\n",
              "      <td>0.585</td>\n",
              "      <td>0.240</td>\n",
              "      <td>0.120</td>\n",
              "      <td>0.570</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.91</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.00</td>\n",
              "      <td>Good</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.274158</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>100053</td>\n",
              "      <td>202</td>\n",
              "      <td>Mixed</td>\n",
              "      <td>non religious</td>\n",
              "      <td>33.7</td>\n",
              "      <td>66.3</td>\n",
              "      <td>6.2</td>\n",
              "      <td>13.4</td>\n",
              "      <td>28.2</td>\n",
              "      <td>70.3</td>\n",
              "      <td>1.5</td>\n",
              "      <td>47.1</td>\n",
              "      <td>26.2</td>\n",
              "      <td>6.3</td>\n",
              "      <td>18.5</td>\n",
              "      <td>136</td>\n",
              "      <td>128</td>\n",
              "      <td>47.2</td>\n",
              "      <td>-0.08</td>\n",
              "      <td>-0.30</td>\n",
              "      <td>0.14</td>\n",
              "      <td>4.29</td>\n",
              "      <td>0.662</td>\n",
              "      <td>0.471</td>\n",
              "      <td>0.515</td>\n",
              "      <td>0.368</td>\n",
              "      <td>0.265</td>\n",
              "      <td>0.625</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.03</td>\n",
              "      <td>Good</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.107210</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      URN   LA GENDER        RELCHAR  ...  en_GENDER  en_RELCHAR  FILCLF  P8PUP_log\n",
              "0  100049  202  Mixed  non religious  ...          2           0     1.0   2.250420\n",
              "1  100050  202  Girls  non religious  ...          1           0     1.0   2.214844\n",
              "2  100051  202  Mixed  non religious  ...          2           0     0.0   2.143015\n",
              "3  100052  202  Mixed  non religious  ...          2           0     0.0   2.274158\n",
              "4  100053  202  Mixed  non religious  ...          2           0     1.0   2.107210\n",
              "\n",
              "[5 rows x 41 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRKud7D0ruKq",
        "outputId": "38e1ba60-cbb5-4160-f2da-0c4a93953665"
      },
      "source": [
        "# K-NN\n",
        "new_X = final_df[['P8PUP_log','FILCLF','en_GENDER','en_RELCHAR','PNORG','PNORB','PSENELSE','PSENELK','PNUMEAL','PNUMENGFL','PNUMFSM','ATT8SCR','P8MEA','P8_BANDING', 'OVERALL_DESTPER', 'NOT_SUSTAINEDPER','UNKNOWNPER']].values\n",
        "y = final_df['Rating_Val'].values\n",
        "kn_clf = neighbors.KNeighborsClassifier()\n",
        "kn_clf.fit(new_X,y)\n",
        "predictions_kn = kn_clf.predict(new_X)\n",
        "metrics.accuracy_score(y, predictions_kn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7265767407947503"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-m8WuAGum4k4",
        "outputId": "68f4c2c6-1419-4aba-a294-8a40cdb183fc"
      },
      "source": [
        "scores_kN = cross_val_score(kn_clf.fit(new_X,y), new_X, y, cv= 5)\n",
        "scores_kN.mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6077393535691968"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqYKMsXmKzht"
      },
      "source": [
        "**Feature Selection Task**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McJYXd2RK4CW"
      },
      "source": [
        "Difference between Filter and Wrapper Method\n",
        "- The Wrapper method gets to loop through every feature available via an algorithm, adding the features that gives the best result for the classifier which leads to a better accuracy while also removing the ones that gives less best result while going through the loop. An advantage is it gives the best accuracy while it interacts with the classifier, however a disadvantage is that it is slow in its process having to loop through every feature\n",
        "- The filter on the other hand uses objective statistics to rank each of the features in order to choose the best feature for the classifier, exmaple of this statistical approach is variance, correlation, independence, mutual information. An advantage of this method is that it is fast when compared with the wrapper method while a disadvantage of this approach is that it ignores interaction with the classifier and just focuses on ranking the features based on statistical means"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lt1CNjG7R0o-"
      },
      "source": [
        "Filter Methods:\n",
        "- Variance: This filter method checks how much difference or variability there are in the feature values as it ignores the features with less variability because it doesn't help with predictions. Advantage of this approach is that it is easy to calculate and can work with unsupervised learning however not having correlation between features which is the feature we are trying to predict is a disadvantage.\n",
        "- Correlation: This checks how much covariance is between features and label, which is checking how much they vary together. That is, how much of the variance in one feature is because of the variance in the other feature.\n",
        "- Mutual information: This filter method measure the amount of information shared between two variables, that is the amount of information one feature tells about another feature. The information in this sense is the measure of entropy in a random selection of a feature value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkX9_xszcr2y"
      },
      "source": [
        "Chosen filter method is the Correlation Method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTGlnMgxUBUQ",
        "outputId": "d113ad3e-0f15-426f-fccf-ebe10f3d4c73"
      },
      "source": [
        "fs = feature_selection.SelectKBest(score_func=feature_selection.f_regression, k=10)\n",
        "X_fs = fs.fit_transform(new_X, y)\n",
        "y = final_df['Rating_Val'].values\n",
        "kn_clf = neighbors.KNeighborsClassifier()\n",
        "kn_clf.fit(X_fs,y)\n",
        "predictions_kn = kn_clf.predict(X_fs)\n",
        "metrics.accuracy_score(y, predictions_kn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7324097703244623"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWO0cl4znGhx",
        "outputId": "8bd90cdb-777c-4507-a33a-a05c9a14c127"
      },
      "source": [
        "scores_kN = cross_val_score(kn_clf.fit(X_fs,y), X_fs, y, cv= 5)\n",
        "scores_kN.mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6084652919043251"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DoYuc9igcRG7",
        "outputId": "c0d69358-eb4d-4a14-ba9d-570d7d311a32"
      },
      "source": [
        "# Logistic Regression\n",
        "log_clf = linear_model.LogisticRegression()\n",
        "log_clf.fit(X_fs,y)\n",
        "predictions_lg = log_clf.predict(X_fs)\n",
        "metrics.accuracy_score(y, predictions_lg)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6401749908858914"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c81pZkMnRlz",
        "outputId": "85debfe7-fe90-4037-c32e-6a75e3152589"
      },
      "source": [
        "scores_log = cross_val_score(log_clf.fit(X_fs,y), X_fs, y, cv= 5)\n",
        "scores_log.mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6405408639463923"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iquKfvofcf9D",
        "outputId": "5100afd6-ae42-4ef0-fe27-38768de47a96"
      },
      "source": [
        "# Naive Bayes\n",
        "na_clf = naive_bayes.GaussianNB()\n",
        "na_clf.fit(X_fs,y)\n",
        "predictions_na = na_clf.predict(X_fs)\n",
        "metrics.accuracy_score(y, predictions_na)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6193948231862924"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmYtZDAKnbEk",
        "outputId": "340704bd-5548-4a4d-dee3-d02787b8453f"
      },
      "source": [
        "scores_nai = cross_val_score(na_clf.fit(X_fs,y), X_fs, y, cv= 5)\n",
        "scores_nai.mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6099218220254478"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMKkh2uodJsE"
      },
      "source": [
        "Applying Wrapper Method using Forward Selection with a random forest classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAwN6Ac1f-b3"
      },
      "source": [
        "- using a train test split for the data for accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "va06PU84Z0YR"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test=train_test_split(final_df.drop(['Rating_Val','GENDER','URN','LA','RELCHAR','Rating'],axis=1),final_df['Rating_Val'],test_size=.2,random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpdgApaeilW5",
        "outputId": "ec22599d-8263-4e80-8c0c-830012fd548a"
      },
      "source": [
        "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# Sequential Forward Selection(sfs)\n",
        "sfs = SFS(RandomForestClassifier(),\n",
        "          k_features=15,\n",
        "          forward=True,\n",
        "          floating=False,\n",
        "          scoring = 'accuracy',\n",
        "          cv = 5)\n",
        "sfs.fit(X_train, y_train)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SequentialFeatureSelector(clone_estimator=True, cv=5,\n",
              "                          estimator=RandomForestClassifier(bootstrap=True,\n",
              "                                                           ccp_alpha=0.0,\n",
              "                                                           class_weight=None,\n",
              "                                                           criterion='gini',\n",
              "                                                           max_depth=None,\n",
              "                                                           max_features='auto',\n",
              "                                                           max_leaf_nodes=None,\n",
              "                                                           max_samples=None,\n",
              "                                                           min_impurity_decrease=0.0,\n",
              "                                                           min_impurity_split=None,\n",
              "                                                           min_samples_leaf=1,\n",
              "                                                           min_samples_split=2,\n",
              "                                                           min_weight_fraction_leaf=0.0,\n",
              "                                                           n_estimators=100,\n",
              "                                                           n_jobs=None,\n",
              "                                                           oob_score=False,\n",
              "                                                           random_state=None,\n",
              "                                                           verbose=0,\n",
              "                                                           warm_start=False),\n",
              "                          floating=False, forward=True, k_features=15, n_jobs=1,\n",
              "                          pre_dispatch='2*n_jobs', scoring='accuracy',\n",
              "                          verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXnj8FhEp7Kh",
        "outputId": "918df3b1-dc75-4c56-9ba3-1440bb925c11"
      },
      "source": [
        "selected_features = X_train.columns[list(sfs.k_feature_idx_)]\n",
        "print(selected_features)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['PNORG', 'PNUMEAL', 'PNUMFSM', 'PPERSABS10', 'P8CILOW', 'EBACCAPS',\n",
            "       'PTL2BASICS_95', 'P8_BANDING', 'UNKNOWNPER', 'NOT_SUSTAINEDPER_DIS',\n",
            "       'UNKNOWNPER_DIS', 'en_GENDER', 'en_RELCHAR', 'FILCLF', 'P8PUP_log'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dC12rNRug-UH",
        "outputId": "e7f6ae86-b1f7-4e65-b56d-3dc46a526751"
      },
      "source": [
        "print(sfs.k_score_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6768485869712193\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnkDjO9dgwiV"
      },
      "source": [
        "Now using the K-NN classifier using the features produced in the wrapper method above(This changes after every run) to get the best accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUsCYByRhKld",
        "outputId": "db260cd3-7d17-415f-8c35-cf9215e1ca76"
      },
      "source": [
        "X_wrp = final_df[['PSENELSE', 'PSENELK', 'PNUMENGFL', 'PNUMFSM', 'PPERSABS10', 'P8PUP',\n",
        "       'ATT8SCR', 'PTL2BASICS_95', 'PTEBACC_E_PTQ_EE', 'P8_BANDING',\n",
        "       'UNKNOWNPER', 'UNKNOWNPER_DIS', 'en_GENDER', 'en_RELCHAR', 'FILCLF']].values\n",
        "y = final_df['Rating_Val'].values\n",
        "kn_clf = neighbors.KNeighborsClassifier()\n",
        "kn_clf.fit(X_wrp,y)\n",
        "predictions_kn = kn_clf.predict(X_wrp)\n",
        "metrics.accuracy_score(y, predictions_kn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7400656215822092"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "577HTmWVnoFY",
        "outputId": "62e36b8a-0691-41da-d79c-e893c53d896a"
      },
      "source": [
        "scores_kN = cross_val_score(kn_clf.fit(X_wrp,y), X_wrp, y, cv= 5)\n",
        "scores_kN.mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6073810378524989"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    }
  ]
}